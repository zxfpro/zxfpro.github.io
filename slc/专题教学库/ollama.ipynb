{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feca05c3-ffb7-422d-8d40-e755708660ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OLLAMA 的使用和部署"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe48ef-a2b6-47ae-9f64-2dbaeff8e468",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 在125上部署ollama server 配置 11435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0d190-e6b4-48f5-8522-6f2de041ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证过的\n",
    "1 OLLAMA_HOST=0.0.0.0 解决外网访问问题\n",
    "2 OLLAMA_MODELS=E:\\ollamaimagers   解决模型默认下载C 盘的问题\n",
    "3 OLLAMA_KEEP_ALIVE=24h     设置模型加载到内存中保持24个小时(默认情况下，模型在卸载之前会在内存中保留 5 分钟)\n",
    "4.OLLAMA_HOST=0.0.0.0:8080  解决修改默认端口11434端口\n",
    "5.OLLAMA_NUM_PARALLEL=2  设置2个用户并发请求\n",
    "6.OLLAMA_MAX_LOADED_MODELS=2 设置同时加载多个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6d12f-36c8-4967-b9dc-202d791f1a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "261c6c65-00d4-4b55-8a41-05f77925b8b7",
   "metadata": {},
   "source": [
    "## 如何在ollama 上加载或者创建自己的模型 GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b732e-9a83-4c7f-9128-9f7282beb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "%% Modelfile\n",
    "\n",
    "FROM ./vicuna-33b.Q4_0.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228f525-336d-4a90-bf47-ba60f9540480",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama create my_model -f Modelfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce1619-5e17-43bc-8eec-db47a041f849",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 导入satetensors\n",
    "\n",
    "https://github.com/ollama/ollama/blob/main/docs/import.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57b8a5-e16c-4809-aa85-1c36ac7a1406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d45d3c6e-a814-439b-b80a-8292b6c5cecd",
   "metadata": {},
   "source": [
    "## 如何编写 Modelfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f80b6-e5f1-45d3-829d-c9a6fb8e28d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "https://github.com/ollama/ollama/blob/main/docs/modelfile.mdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944f010-6166-422b-a5f6-60bb3ca3ea86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### llama系列 如何不乱说的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1b372-992b-47be-b85b-3c4bd8637619",
   "metadata": {},
   "outputs": [],
   "source": [
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{{ system_prompt }}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{{ user_msg_1 }}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{{ model_answer_1 }}<|eot_id|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f159fb4-2528-4241-b155-b6153854ac3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc79657-df1a-48c0-803c-a322e718a2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a819c975-7208-469f-98b9-ee8fa0b7dc64",
   "metadata": {},
   "source": [
    "## 启动服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044a499-eddd-42e2-9c4a-4e0a81fe882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 tmux 中创建 执行 ollama serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d5a0c-1e97-4d58-875e-551cde1da181",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://192.168.8.125:11435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed2f7e-4235-4fe2-903e-32fa06bdd300",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://192.168.8.126:11435"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8455e8-d6d4-48b2-9e7d-32252abf0062",
   "metadata": {},
   "source": [
    "## 验证启动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630ab18-0d2d-457a-aad6-aefb334b7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "get 请求 http://192.168.8.126:11435 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf143ca-ca19-4903-9e88-1f99c0318b55",
   "metadata": {},
   "source": [
    "## 查看模型列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa367a7-5842-416c-ab41-dcab7e1f8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61814e0e-da55-417b-8118-ba3c4778430e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48765566-3266-48b8-a293-2f2cd8f6ebe1",
   "metadata": {},
   "source": [
    "## 使用openai 调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb18f85-7a90-4044-ad08-c2f9a7d9fd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d53c5-8ba9-41fe-b767-127538a8415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 443 ms, sys: 104 ms, total: 547 ms\n",
      "Wall time: 5.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='a',base_url='http://192.168.8.126:11435/v1')\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"llama3:70b\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"请使用中文,帮我介绍一下北京!\"}\n",
    "  ],\n",
    "    stream=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2a39d-0698-478b-ad83-7d3b9af02b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='北京是中国最大的城市和政治中心，也是全世界人口最大的一座城市。它位于北方的太行山前坡，气候温润、四季更替。\\n\\n历史\\n--------\\n\\n作为中國古代最先进的都城，北京拥有5000多年的悠久历史。从夏朝到清朝，都是中国的首都，如今已经成为全球性大都市。著名的地标建筑有：\\n\\n皇宫Forbidden城墙Great Wall of China\\n天坛（Temple of Heaven）故宫\\n故宫，是世界上最大、最完美的皇家宫殿群。\\n\\n文化生活\\n--------\\n\\n在城市中心區域設有多個博物館、劇場和藝術展，包括：\\n中國國家博物館\\n\\n京剧和音樂也是一種本地的表演藝術。當年北京城內的一些地方如鼓楼等還有許多著名的京剧院所在地。\\n\\n飲食\\n--------\\n\\n有一大半是面点（汉堡、馅饼等）。但更多的地方你会发现口味獨特的北方菜，例如：小笼包烫手仔餅\\n\\n附近地区还有一個非常著名的小吃街-王府井。\\n\\n交通及公共交通服务 \\n------------------------\\n\\n这座城市拥有世界最好的地铁系统，有超过50条地下线路。自從清代開始到1900年，中国便有使用火车，但它只是在1912年於四通八达的京包铁路开始正式地運行。然而，从1864年到1893年，在前两次奥林匹克运动会前，這條主要來往北京城到保定（即太原）的鐵路都一直在运作。\\n\\n随着这座城市不断發展起來，很多外国旅程都開始進入這座都市。包括一些外國的鐵路系統，外国的旅游线都开始在这里发展。', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fabeba-83f7-4a0a-aa53-dbf0f62687d4",
   "metadata": {},
   "source": [
    "## 流式方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab12d1d-872c-4c4b-a0c8-405347cf4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='a',base_url='http://192.168.8.125:11435/v1')\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"llama3\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ],\n",
    "    stream=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47c35462-58b9-4dfc-a97e-16555d23036a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceDelta(content='Hi', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' there', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='!', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' It', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=\"'s\", function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' nice', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' to', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' meet', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' you', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='!', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' Is', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' there', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' something', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' I', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' can', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' help', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' you', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' with', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=',', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' or', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' would', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' you', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' like', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' to', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' chat', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' about', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' something', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' in', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' particular', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='?', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' I', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=\"'m\", function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' all', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' ears', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' (', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='or', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' rather', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=',', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' all', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' text', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=')!', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for chunk in completion:\n",
    "  print(chunk.choices[0].delta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
