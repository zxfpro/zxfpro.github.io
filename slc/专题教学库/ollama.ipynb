{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feca05c3-ffb7-422d-8d40-e755708660ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OLLAMA 的使用和部署"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe48ef-a2b6-47ae-9f64-2dbaeff8e468",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 在125上部署ollama server 配置 11435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6336e14a-6880-40e5-888e-11bf5c002d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 OLLAMA_HOST=0.0.0.0 解决外网访问问题\n",
    "2 OLLAMA_MODELS=E:\\ollamaimagers   解决模型默认下载C 盘的问题\n",
    "3 OLLAMA_KEEP_ALIVE=24h     设置模型加载到内存中保持24个小时(默认情况下，模型在卸载之前会在内存中保留 5 分钟)\n",
    "4.OLLAMA_HOST=0.0.0.0:8080  解决修改默认端口11434端口\n",
    "5.OLLAMA_NUM_PARALLEL=2  设置2个用户并发请求\n",
    "6.OLLAMA_MAX_LOADED_MODELS=2 设置同时加载多个模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c6c65-00d4-4b55-8a41-05f77925b8b7",
   "metadata": {},
   "source": [
    "## 如何在ollama 上加载或者创建自己的模型 GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b732e-9a83-4c7f-9128-9f7282beb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "%% Modelfile\n",
    "\n",
    "FROM ./vicuna-33b.Q4_0.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228f525-336d-4a90-bf47-ba60f9540480",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama create my_model -f Modelfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce1619-5e17-43bc-8eec-db47a041f849",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 导入satetensors\n",
    "\n",
    "https://github.com/ollama/ollama/blob/main/docs/import.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57b8a5-e16c-4809-aa85-1c36ac7a1406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d45d3c6e-a814-439b-b80a-8292b6c5cecd",
   "metadata": {},
   "source": [
    "## 如何编写 Modelfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f80b6-e5f1-45d3-829d-c9a6fb8e28d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "https://github.com/ollama/ollama/blob/main/docs/modelfile.mdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944f010-6166-422b-a5f6-60bb3ca3ea86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### llama系列 如何不乱说的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1b372-992b-47be-b85b-3c4bd8637619",
   "metadata": {},
   "outputs": [],
   "source": [
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{{ system_prompt }}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{{ user_msg_1 }}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{{ model_answer_1 }}<|eot_id|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f159fb4-2528-4241-b155-b6153854ac3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc79657-df1a-48c0-803c-a322e718a2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a819c975-7208-469f-98b9-ee8fa0b7dc64",
   "metadata": {},
   "source": [
    "## 启动服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044a499-eddd-42e2-9c4a-4e0a81fe882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 tmux 中创建 执行 ollama serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d5a0c-1e97-4d58-875e-551cde1da181",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://192.168.8.125:11435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed2f7e-4235-4fe2-903e-32fa06bdd300",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://192.168.8.126:11435"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8455e8-d6d4-48b2-9e7d-32252abf0062",
   "metadata": {},
   "source": [
    "## 验证启动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630ab18-0d2d-457a-aad6-aefb334b7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "get 请求 http://192.168.8.126:11435 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf143ca-ca19-4903-9e88-1f99c0318b55",
   "metadata": {},
   "source": [
    "## 查看模型列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa367a7-5842-416c-ab41-dcab7e1f8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a40ba-c7ec-4e6f-a983-918707ad2806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61814e0e-da55-417b-8118-ba3c4778430e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48765566-3266-48b8-a293-2f2cd8f6ebe1",
   "metadata": {},
   "source": [
    "## 使用openai 调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c8d53c5-8ba9-41fe-b767-127538a8415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.6 ms, sys: 11.4 ms, total: 56 ms\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='a',base_url='http://192.168.8.126:11435/v1')\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"llama3:70b\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"请使用中文,帮我介绍一下北京!\"}\n",
    "  ],\n",
    "    stream=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aa2a39d-0698-478b-ad83-7d3b9af02b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='很高兴！北京是一座历史悠久、文化丰富的城市，位于中国华北平原的中心。以下是关于北京的一些基本信息：\\n\\n**自然环境**\\n\\n* 北京地处华北平原，海拔高度平均为40-60米。\\n* 城市四周环绕着群山，包括西山、北岳、东灵山和南岱山等。\\n\\n**历史文化**\\n\\n* 北京是中国十三朝古都之一，有3000多年的历史。\\n* 城市中拥有大量的历史遗址和文物，如长城、明陵、故宫、颐和园等。\\n* 北京还保留着许多传统的文化和习俗，例如京剧、北京烤鸭、豆汁儿等。\\n\\n**旅游景点**\\n\\n* 长城（Badaling Great Wall, Mutianyu Great Wall）：中国最著名的古代军事防御工事之一。\\n* 故宫（Forbidden City）：明清两朝皇宫，中国最大、保存最好的 palace complex。\\n* 颐和园（Summer Palace）：中国最大的皇家园林，拥有许多美丽的湖泊、岛屿和殿宇。\\n* 天安门广场（Tiananmen Square）：中国政治中心，也是中国最大的城市广场。\\n\\n**生活便利**\\n\\n* 北京交通发达，有两条国际机场（首都国际机场、 大兴国际机场），多条铁路线路和高速公路。\\n* 城市中有许多大型购物中心和市场，如王府井、银泰中心、潘家园等。\\n* 北京拥有世界一流的医疗资源，例如北京大学人民医院、中国医学科学院等。\\n\\n**美食**\\n\\n* 北京烤鸭：一种传统的北京小吃，以烤制的鸭子为主。\\n* 炒面条：一种简单易做的小吃，用炒好的面条、蔬菜和肉末组成。\\n* 豆汁儿：一种甜味的传统饮料，用豌豆、红糖和水混合而成。\\n\\n这些只是关于北京的一个小小的介绍。如果您想知道更多关于北京的事情，我很高兴地为您服务！ 😊', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fabeba-83f7-4a0a-aa53-dbf0f62687d4",
   "metadata": {},
   "source": [
    "## 流式方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab12d1d-872c-4c4b-a0c8-405347cf4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='a',base_url='http://192.168.8.125:11435/v1')\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"llama3\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ],\n",
    "    stream=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47c35462-58b9-4dfc-a97e-16555d23036a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceDelta(content='Hi', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' there', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='!', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' It', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=\"'s\", function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' nice', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' to', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' meet', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' you', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='!', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' Is', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' there', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' something', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' I', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' can', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' help', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' you', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' with', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=',', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' or', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' would', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' you', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' like', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' to', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' chat', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' about', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' something', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' in', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' particular', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='?', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' I', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=\"'m\", function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' all', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' ears', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' (', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='or', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' rather', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=',', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' all', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=' text', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content=')!', function_call=None, role='assistant', tool_calls=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for chunk in completion:\n",
    "  print(chunk.choices[0].delta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
