{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0fcce40-a62b-414d-bdbb-70f87d6d76b0",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca041be-b311-4d57-8b6c-e22ea1dfde72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 如何使用fire 工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e25aa-49eb-42ae-a9e2-04ee6088e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fire\n",
    "from .prompts import fix\n",
    "import os\n",
    "from zxftools.llms import get_llm\n",
    "\n",
    "def ai_fix(file_path=''):\n",
    "    assert os.path.isfile(file_path)\n",
    "    llm = get_llm(model=os.environ.get('aigen_llm') or 'gpt-3.5-turbo-0613')\n",
    "\n",
    "    with open(file_path,'r') as f:\n",
    "        code = f.read()\n",
    "    result = llm.complete(fix.format(code=code))\n",
    "\n",
    "    with open(file_path,'w') as f:\n",
    "        f.write(result.text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fire.Fire(ai_fix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5984779-dd1b-43ba-aa1f-46e8afe77187",
   "metadata": {},
   "source": [
    "## 编写一个装饰器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba2f401-306b-4f9c-8f00-013395173583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def decorator(a = None):\n",
    "    \"\"\"\n",
    "    一个装饰器的编写demo\n",
    "    \"\"\"\n",
    "    def outer_packing(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            result = func(*args, **kwargs)\n",
    "            print(a,'a')\n",
    "            print(func.__name__)  # 函数名\n",
    "            print(args)  # (1, 2)\n",
    "            print(kwargs)  # {'c': 3}\n",
    "            return result\n",
    "        return wrapper\n",
    "    return outer_packing\n",
    "\n",
    "hard_dependencies = ('time',)\n",
    "check_package(hard_dependencies=hard_dependencies,check=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96af8c9-ab85-41f5-9aad-08a0c4a4a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(base_url=\"https://api.bianxieai.com/v1\",\n",
    "                api_key=os.environ.get('bianxieai_API_KEY'))\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"claude-3-5-sonnet-20240620\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "if __name__ == '__main__':\n",
    "    print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31363eec-d92c-440c-9640-80fb5475a62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d285adc-aa9a-4bc0-95e5-f52a652af761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aa(x = 1,b = 3,**kwargs):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059da645-d77e-4a1d-90f3-256123c3d9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "aa(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405e591b-3c78-4180-a807-ecd41d39e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def thread_list(f, params: types.GeneratorType or list, processes=4, chunksize: int = 1):\n",
    "        \"\"\"\n",
    "        1 必须到 if __name__ == '__main__': 下执行\n",
    "        \"\"\"\n",
    "        pool = Pool(processes)\n",
    "        if isinstance(params, types.GeneratorType):\n",
    "            results = pool.imap(f, params, chunksize=chunksize)\n",
    "        else:\n",
    "            results = pool.map(f, params, chunksize=chunksize)\n",
    "        pool.close()\n",
    "        return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
