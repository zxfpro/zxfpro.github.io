{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e53edd6-cd1f-4715-933f-a9a0074d7977",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 11 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71c37dd-491a-43a0-8b9a-c7684b302ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zxfMLtools_dev.models import BaseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ae7e3f-16c4-4bf8-80f9-365eb3158d08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 多头自注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be14bf5-c935-4e87-9924-43487bd95b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Head(BaseNet):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "    \n",
    "#Multi-Headed Self Attention\n",
    "class MultiHeadAttention(BaseNet):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caaef87-c8e7-4d06-bcb6-ebcf6495c186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef7b31-eeca-42f8-bcfe-1a36f981afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 专家模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3b705-4914-49be-8fbe-b4fcde6f73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(BaseNet):\n",
    "    \"\"\" An MLP is a simple linear layer followed by a non-linearity i.e. each Expert \"\"\"\n",
    "\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dfa3c34-43b1-4be2-b0cd-a7f368b1b1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 路由模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecb9ebfa-2f0d-4da1-a765-034d57606805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#noisy top-k gating\n",
    "class NoisyTopkRouter(BaseNet):\n",
    "    def __init__(self, n_embed, num_experts, top_k):\n",
    "        super(NoisyTopkRouter, self).__init__()\n",
    "        self.top_k = top_k\n",
    "        #layer for router logits\n",
    "        self.topkroute_linear = nn.Linear(n_embed, num_experts)\n",
    "        self.noise_linear =nn.Linear(n_embed, num_experts)\n",
    "\n",
    "    \n",
    "    def forward(self, mh_output):\n",
    "        # mh_ouput is the output tensor from multihead self attention block\n",
    "        logits = self.topkroute_linear(mh_output)\n",
    "\n",
    "        #Noise logits\n",
    "        noise_logits = self.noise_linear(mh_output)\n",
    "\n",
    "        #Adding scaled unit gaussian noise to the logits\n",
    "        noise = torch.randn_like(logits)*F.softplus(noise_logits)\n",
    "        noisy_logits = logits + noise\n",
    "\n",
    "        top_k_logits, indices = noisy_logits.topk(self.top_k, dim=-1)\n",
    "        zeros = torch.full_like(noisy_logits, float('-inf'))\n",
    "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
    "        router_output = F.softmax(sparse_logits, dim=-1)\n",
    "        return router_output, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a83627-5a81-4de4-9242-2050b37a24fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219584e-28d3-4ae7-b02a-f88aa3234bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e89d15-3f7b-4455-b23b-1eccc9e4ba80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1eede-ffec-46bb-a385-d2dd50cee948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b79f420-198c-4f3c-9899-1fc71ab63ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now create the sparse mixture of experts module\n",
    "class MoE(BaseNet):\n",
    "    def __init__(self, n_embed, num_experts, top_k):\n",
    "        super().__init__()\n",
    "        self.router = NoisyTopkRouter(n_embed, num_experts, top_k)\n",
    "        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        gating_output, indices = self.router(x)\n",
    "        final_output = torch.zeros_like(x)\n",
    "\n",
    "        # Reshape inputs for batch processing\n",
    "        flat_x = x.view(-1, x.size(-1))\n",
    "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
    "\n",
    "        # Process each expert in parallel\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            # Create a mask for the inputs where the current expert is in top-k\n",
    "            expert_mask = (indices == i).any(dim=-1)\n",
    "            flat_mask = expert_mask.view(-1)\n",
    "\n",
    "            if flat_mask.any():\n",
    "                expert_input = flat_x[flat_mask]\n",
    "                expert_output = expert(expert_input)\n",
    "\n",
    "                # Extract and apply gating scores\n",
    "                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)\n",
    "                weighted_output = expert_output * gating_scores\n",
    "\n",
    "                # Update final output additively by indexing and adding\n",
    "                final_output[expert_mask] += weighted_output.squeeze(1)\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d73af3-e036-4a7c-95d0-3621a66e3cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch 中的 out = torch.cat([h(x) for h in self.heads], dim=-1) 在做什么 输入输出形状是什么样的\n",
      "\n",
      "\n",
      "\n",
      "这行代码是将多个头部的输出连接起来。输入是一个列表，列表中的每个元素都是一个头部函数 h(x) 的输出。输出是将这些输出连接起来的张量。\n",
      "\n",
      "假设列表中有 n 个元素，每个元素的形状为 (batch_size, d)，其中 batch_size 是批量大小，d 是每个头部的输出维度。则输出的形状为 (batch_size, n*d)，即将每个头部的输出按照最后一个维度连接起来。\n"
     ]
    }
   ],
   "source": [
    "%%aigen -a torch 中的 out = torch.cat([h(x) for h in self.heads], dim=-1) 在做什么 输入输出形状是什么样的\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f2d006-fcfe-4b8e-8b64-c367819999ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea64bf-4209-4c00-ba75-ed9a2fbb3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6a1c8-f0ef-4c45-a2c8-ebfc7c322443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = torch.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086326f-6e27-4b19-82af-b759b3bbc8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b395700-4b2c-423b-934f-45be5ab335c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a,b],dim=).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246224a3-6031-4a57-8d32-6f1f87215436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee726f0-55e4-425f-adc4-664d32622517",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ab770-3142-42f2-8988-ddb9697ebcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full_like(tt, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36955866-1d68-41b7-bde4-2a260c867ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0701, -1.0484, -1.9100],\n",
       "        [ 0.4687,  1.8424,  1.7367]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c733c-d3bb-4af5-aad1-a2469cd3b141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 0.0701, -1.0484],\n",
       "        [ 1.8424,  1.7367]]),\n",
       "indices=tensor([[0, 1],\n",
       "        [1, 2]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.topk(2,dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39e5bd34-c96d-4c6f-b04d-a19e9334e090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_embed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mMultiHeadAttention.__init__\u001b[0;34m(self, num_heads, head_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_heads, head_size):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([Head(head_size) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_heads)])\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(n_embed, n_embed)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(dropout)\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_heads, head_size):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mHead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_heads)])\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(n_embed, n_embed)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(dropout)\n",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m, in \u001b[0;36mHead.__init__\u001b[0;34m(self, head_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, head_size):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[43mn_embed\u001b[49m, head_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(n_embed, head_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(n_embed, head_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_embed' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "MultiHeadAttention(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a17ee-72d3-4f13-a737-9eca039a3dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
