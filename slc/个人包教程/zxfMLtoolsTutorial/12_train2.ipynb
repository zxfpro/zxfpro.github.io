{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09dc3277-0728-474b-8b9f-88305df136fb",
   "metadata": {},
   "source": [
    "# 12 Train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43cba78-22e9-4aa7-804f-4481e08c1f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d6fc7f-bc04-4cfe-bf65-9c5bf4058574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zxfMLtools import parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df996c71-3cce-4004-8625-09c7c0b9f97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "a = parallel.QNet(nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428e968a-0c15-48c8-b24b-138dd712688e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ab = torch.ones(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac5aab5-dd6a-4229-9d7f-7bfa3ad9449a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0610, -0.0859, -0.1604],\n",
       "         [ 0.4099, -0.2556, -0.2778]],\n",
       "\n",
       "        [[ 0.3399, -0.0267, -0.0226],\n",
       "         [-0.1978,  0.0328, -0.2465]],\n",
       "\n",
       "        [[-0.3183, -0.0231, -0.1164],\n",
       "         [-0.7574, -0.8539, -0.7438]],\n",
       "\n",
       "        [[ 0.1795,  0.3827,  0.4585],\n",
       "         [ 0.0576,  0.1740,  0.3119]],\n",
       "\n",
       "        [[ 0.0790, -0.0171,  0.1939],\n",
       "         [-0.2159, -0.0076, -0.0815]],\n",
       "\n",
       "        [[ 0.1499, -0.1871, -0.2393],\n",
       "         [ 0.3053,  0.3216, -0.0703]],\n",
       "\n",
       "        [[ 0.0159, -0.5835, -0.2497],\n",
       "         [ 0.1518,  0.0771, -0.1408]],\n",
       "\n",
       "        [[ 0.1502, -0.0749,  0.0711],\n",
       "         [ 0.2266,  0.1728,  0.2565]],\n",
       "\n",
       "        [[ 0.3916,  0.0105, -0.2505],\n",
       "         [ 0.2454, -0.0567, -0.3095]],\n",
       "\n",
       "        [[ 0.2556, -0.2946, -0.1741],\n",
       "         [ 0.0266, -0.0511, -0.1432]],\n",
       "\n",
       "        [[-0.1701,  0.1068,  0.1488],\n",
       "         [-0.1522, -0.1719, -0.1513]],\n",
       "\n",
       "        [[-0.1319, -0.0223, -0.0832],\n",
       "         [-0.2705,  0.0085, -0.1288]],\n",
       "\n",
       "        [[ 0.5235,  0.2958,  0.0374],\n",
       "         [ 0.2400,  0.2653,  0.4740]],\n",
       "\n",
       "        [[ 0.4058,  0.3421,  0.3144],\n",
       "         [ 0.5472,  0.1352,  0.3178]],\n",
       "\n",
       "        [[ 0.2937, -0.0755, -0.2143],\n",
       "         [ 0.1581,  0.0462, -0.0259]],\n",
       "\n",
       "        [[-0.2495,  0.0170,  0.0513],\n",
       "         [-0.0869, -0.1015,  0.1406]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "833bc6c4-fda7-457d-b2f6-f212ea4d11f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNet(\n",
       "  (net): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9db9375-590b-4470-bd92-46ba50311d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.onnx.export(a,ab,'aa.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b7b01-3993-4ff8-8207-a5d34dce0367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617749db-d56a-47e2-b406-86be5988b54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b5857-5641-462e-8b9d-7c4ce753a770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a6427-3560-4da4-afa5-b30823a094f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40ff002-b532-4a1e-a72c-a77ab613356a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc36529-1c58-4e75-8e65-d8a6819ec420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = parallel.QNet(nn.Sequential(nn.Linear(4,30),nn.ReLU(),\n",
    "              nn.Linear(30,40),nn.ReLU(),\n",
    "              nn.Linear(40,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8493c2dd-317d-47f0-b780-fb01189e8c81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5671,  0.2377], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(torch.Tensor(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3c97fcf-605c-4800-8f96-6fd889febc1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = a(torch.Tensor(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e6a4d991-b6ab-4874-9103-f0073e27e499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "los = (t - torch.Tensor([0.0,1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "152aa49c-3ae5-48f2-b69e-538e14294ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = los.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e4ff4bbf-703f-4638-a59d-a2aadbb26731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "19e1394a-5752-4356-93b1-13bd2de07979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd3e65a6-a2fe-4df0-b5a6-792455706493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "880d3929-f72e-402e-b81c-4f81c49db1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b237acd1-1bca-40fb-bee8-9525f7ce4849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0898e+26, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losss(t,torch.Tensor([0.0,1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8166bf6-0044-4b6e-98a1-fdda48d02df3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-inf, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82e8930b-6b42-4590-ba53-ea443850ae93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class pp():\n",
    "    def __init__(self):\n",
    "        self.a = parallel.QNet(nn.Sequential(nn.Linear(4,30),nn.ReLU(),\n",
    "              nn.Linear(30,40),nn.ReLU(),\n",
    "              nn.Linear(40,2)))\n",
    "    \n",
    "    def update(self,data):\n",
    "        data = torch.Tensor(4) # TODO wait replace\n",
    "        end = self.a(data)\n",
    "        k = sum(end - torch.Tensor([0,1]))\n",
    "        k.backward()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23ef060f-5650-47a1-9747-0df220985d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNet(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=30, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=40, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2af4fee-45e4-47ae-b1ca-561cdc2cdd93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c99c98dc-1d6f-4f8b-9dc2-9a7f756c8a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87cfe7-966a-4b46-a94c-6fe2f276ce2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9abb19b-737e-47d6-af8e-17be086aa4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_grad_hook(module, grad_input, grad_output):\n",
    "    print(f\"module: {module}\")\n",
    "    print(f\"grad_input: {grad_input[0].shape}, {grad_input[0].norm()}\")\n",
    "    print(f\"grad_output: {grad_output[0].shape}, {grad_output[0].norm()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "caaf14e4-798d-4026-a5d2-332af9c7c5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear = nn.Linear(10, 5)\n",
    "weight_hook = linear.weight.register_hook(print_grad_hook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f23e7ece-0913-4aba-a7e2-902a285ed7cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_grad_hook() missing 2 required positional arguments: 'grad_input' and 'grad_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m linear(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(output, target)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py310/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: print_grad_hook() missing 2 required positional arguments: 'grad_input' and 'grad_output'"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 10)\n",
    "target = torch.randn(1, 5)\n",
    "output = linear(input)\n",
    "loss = nn.MSELoss()(output, target)\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fe20ac-fe9c-4faf-b76d-cce34aa8d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd538a-dea2-4bf6-b105-758e15efd2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56011d36-d0ca-418c-b086-8dd8710a941c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a4d2118-7b9e-4d05-85c4-244801765047",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear(in_features=84, out_features=10, bias=True)\n",
      "---------- Incoming Gradients ----------\n",
      "\n",
      "Incoming Grad value: tensor([ 0.0990,  0.0985,  0.0927,  0.0964,  0.1063,  0.0921,  0.0964, -0.8819,\n",
      "         0.1031,  0.0973])\n",
      "\n",
      "Upstream Grad value: tensor([[ 0.0990,  0.0985,  0.0927,  0.0964,  0.1063,  0.0921,  0.0964, -0.8819,\n",
      "          0.1031,  0.0973]])\n",
      "grad_input: torch.Size([10]), 0.9296876788139343\n",
      "grad_output: torch.Size([1, 10]), 0.9296876788139343\n",
      "\n",
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "---------- Incoming Gradients ----------\n",
      "\n",
      "Incoming Grad value: tensor([ 0.0990,  0.0985,  0.0927,  0.0964,  0.1063,  0.0921,  0.0964, -0.8819,\n",
      "         0.1031,  0.0973])\n",
      "\n",
      "Upstream Grad value: tensor([[ 0.0990,  0.0985,  0.0927,  0.0964,  0.1063,  0.0921,  0.0964, -0.8819,\n",
      "          0.1031,  0.0973]])\n",
      "grad_input: torch.Size([10]), 0.9296876788139343\n",
      "grad_output: torch.Size([1, 10]), 0.9296876788139343\n",
      "\n",
      "Linear(in_features=120, out_features=84, bias=True)\n",
      "---------- Incoming Gradients ----------\n",
      "\n",
      "Incoming Grad value: tensor([ 0.0000,  0.0000, -0.0976, -0.0776, -0.0113, -0.0063,  0.0341, -0.0091,\n",
      "         0.0000, -0.0564,  0.0000,  0.0000,  0.0492,  0.0000, -0.0649,  0.0000,\n",
      "         0.0000,  0.0968,  0.0000,  0.1088,  0.0000, -0.0246,  0.0372, -0.0307,\n",
      "         0.0306,  0.0692, -0.0941,  0.0000,  0.0103, -0.0361,  0.0000, -0.0610,\n",
      "        -0.0004,  0.0000,  0.0000,  0.0436,  0.0000,  0.0000,  0.0520,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.1099,  0.0000, -0.0021,  0.0002,  0.0216,\n",
      "        -0.0951, -0.0926,  0.0681, -0.1080,  0.0103,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0747, -0.0041,  0.0420,  0.0000, -0.0014,\n",
      "         0.0000,  0.0843,  0.1065,  0.0330,  0.0645,  0.0000,  0.0000, -0.1013,\n",
      "         0.0000,  0.0000, -0.0683,  0.0000,  0.0000, -0.0419, -0.0691, -0.0817,\n",
      "        -0.0646, -0.0418, -0.0561,  0.0000])\n",
      "\n",
      "Upstream Grad value: tensor([[ 0.0000,  0.0000, -0.0976, -0.0776, -0.0113, -0.0063,  0.0341, -0.0091,\n",
      "          0.0000, -0.0564,  0.0000,  0.0000,  0.0492,  0.0000, -0.0649,  0.0000,\n",
      "          0.0000,  0.0968,  0.0000,  0.1088,  0.0000, -0.0246,  0.0372, -0.0307,\n",
      "          0.0306,  0.0692, -0.0941,  0.0000,  0.0103, -0.0361,  0.0000, -0.0610,\n",
      "         -0.0004,  0.0000,  0.0000,  0.0436,  0.0000,  0.0000,  0.0520,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000, -0.1099,  0.0000, -0.0021,  0.0002,  0.0216,\n",
      "         -0.0951, -0.0926,  0.0681, -0.1080,  0.0103,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000, -0.0747, -0.0041,  0.0420,  0.0000, -0.0014,\n",
      "          0.0000,  0.0843,  0.1065,  0.0330,  0.0645,  0.0000,  0.0000, -0.1013,\n",
      "          0.0000,  0.0000, -0.0683,  0.0000,  0.0000, -0.0419, -0.0691, -0.0817,\n",
      "         -0.0646, -0.0418, -0.0561,  0.0000]])\n",
      "grad_input: torch.Size([84]), 0.43599632382392883\n",
      "grad_output: torch.Size([1, 84]), 0.43599632382392883\n",
      "\n",
      "Linear(in_features=400, out_features=120, bias=True)\n",
      "---------- Incoming Gradients ----------\n",
      "\n",
      "Incoming Grad value: tensor([-1.7695e-02,  1.3895e-02, -1.3146e-02,  0.0000e+00, -2.6369e-02,\n",
      "         3.1664e-02,  2.6736e-02,  0.0000e+00,  1.3134e-02, -7.6771e-03,\n",
      "        -2.1510e-03,  2.0286e-02,  0.0000e+00,  2.6287e-02,  1.7755e-03,\n",
      "         0.0000e+00, -1.4436e-04,  2.5398e-02, -1.0850e-02, -3.9383e-02,\n",
      "        -9.8456e-03, -2.0813e-02, -2.8759e-02,  0.0000e+00, -1.1960e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -8.7115e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -3.4241e-02, -1.0405e-02,  0.0000e+00,\n",
      "         0.0000e+00,  8.2243e-03, -2.7679e-02,  0.0000e+00,  4.2322e-02,\n",
      "         0.0000e+00,  0.0000e+00,  6.9768e-02,  0.0000e+00,  3.2919e-03,\n",
      "         0.0000e+00, -7.6362e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -3.6966e-03,  0.0000e+00, -1.4890e-02,  5.1680e-03,  0.0000e+00,\n",
      "         0.0000e+00,  1.1462e-02,  0.0000e+00,  0.0000e+00,  6.9445e-04,\n",
      "         0.0000e+00, -5.0147e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.9891e-02,  1.0723e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -9.8940e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -1.6801e-02, -4.4199e-02,  0.0000e+00, -3.3956e-02,  0.0000e+00,\n",
      "        -1.6591e-02, -5.7921e-03,  8.9135e-03, -2.7128e-02, -2.6416e-02,\n",
      "         0.0000e+00, -2.5234e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -1.6650e-02,  1.3110e-03,  0.0000e+00,  2.6550e-02,  0.0000e+00,\n",
      "        -2.0995e-03,  2.1046e-02,  0.0000e+00, -2.2325e-02,  0.0000e+00,\n",
      "        -3.4487e-02,  0.0000e+00, -6.4695e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  9.7386e-03, -2.1149e-02, -3.6808e-02,  0.0000e+00,\n",
      "         0.0000e+00,  2.4474e-02,  2.8015e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  3.2823e-02,  0.0000e+00, -4.5370e-05, -2.9236e-02])\n",
      "\n",
      "Upstream Grad value: tensor([[-1.7695e-02,  1.3895e-02, -1.3146e-02,  0.0000e+00, -2.6369e-02,\n",
      "          3.1664e-02,  2.6736e-02,  0.0000e+00,  1.3134e-02, -7.6771e-03,\n",
      "         -2.1510e-03,  2.0286e-02,  0.0000e+00,  2.6287e-02,  1.7755e-03,\n",
      "          0.0000e+00, -1.4436e-04,  2.5398e-02, -1.0850e-02, -3.9383e-02,\n",
      "         -9.8456e-03, -2.0813e-02, -2.8759e-02,  0.0000e+00, -1.1960e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -8.7115e-03,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.4241e-02, -1.0405e-02,  0.0000e+00,\n",
      "          0.0000e+00,  8.2243e-03, -2.7679e-02,  0.0000e+00,  4.2322e-02,\n",
      "          0.0000e+00,  0.0000e+00,  6.9768e-02,  0.0000e+00,  3.2919e-03,\n",
      "          0.0000e+00, -7.6362e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.6966e-03,  0.0000e+00, -1.4890e-02,  5.1680e-03,  0.0000e+00,\n",
      "          0.0000e+00,  1.1462e-02,  0.0000e+00,  0.0000e+00,  6.9445e-04,\n",
      "          0.0000e+00, -5.0147e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          3.9891e-02,  1.0723e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -9.8940e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.6801e-02, -4.4199e-02,  0.0000e+00, -3.3956e-02,  0.0000e+00,\n",
      "         -1.6591e-02, -5.7921e-03,  8.9135e-03, -2.7128e-02, -2.6416e-02,\n",
      "          0.0000e+00, -2.5234e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.6650e-02,  1.3110e-03,  0.0000e+00,  2.6550e-02,  0.0000e+00,\n",
      "         -2.0995e-03,  2.1046e-02,  0.0000e+00, -2.2325e-02,  0.0000e+00,\n",
      "         -3.4487e-02,  0.0000e+00, -6.4695e-03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  9.7386e-03, -2.1149e-02, -3.6808e-02,  0.0000e+00,\n",
      "          0.0000e+00,  2.4474e-02,  2.8015e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  3.2823e-02,  0.0000e+00, -4.5370e-05, -2.9236e-02]])\n",
      "grad_input: torch.Size([120]), 0.1898471564054489\n",
      "grad_output: torch.Size([1, 120]), 0.1898471564054489\n",
      "\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "---------- Incoming Gradients ----------\n",
      "\n",
      "Incoming Grad value: tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.9060e-03,  0.0000e+00,  1.0559e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  3.7695e-03],\n",
      "          [-3.1380e-03,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            3.5134e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.4781e-03,\n",
      "            6.9158e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  2.0676e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  3.9534e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00, -1.1841e-02,  0.0000e+00,  ..., -4.0667e-03,\n",
      "            0.0000e+00,  2.1513e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00, -3.8708e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.7465e-03,  0.0000e+00,  0.0000e+00,  ..., -6.0840e-03,\n",
      "            1.2648e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.1685e-02,\n",
      "            0.0000e+00,  4.3147e-03],\n",
      "          [ 0.0000e+00, -2.0714e-03,  8.0317e-03,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  9.3004e-05,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  2.8332e-03],\n",
      "          [ 0.0000e+00,  2.0035e-03,  1.0572e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -8.0112e-03,\n",
      "            0.0000e+00, -1.7121e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -2.5156e-03,  ...,  0.0000e+00,\n",
      "           -5.2514e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  3.9207e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 1.5394e-02,  0.0000e+00,  3.9897e-03,  ...,  0.0000e+00,\n",
      "            2.0178e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00, -5.3560e-03, -4.1836e-04,  ...,  0.0000e+00,\n",
      "           -9.4232e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-5.0074e-04,  0.0000e+00, -1.0326e-02,  ...,  0.0000e+00,\n",
      "           -7.1228e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00, -2.1819e-04,  0.0000e+00,  ...,  7.6706e-03,\n",
      "           -8.3796e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [-6.4681e-03,  0.0000e+00,  0.0000e+00,  ..., -1.2308e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 1.5349e-03,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            4.3688e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.8270e-03,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.1386e-02,  0.0000e+00, -8.6323e-04,  ...,  0.0000e+00,\n",
      "            5.3075e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -2.5249e-03,  ...,  0.0000e+00,\n",
      "           -3.1486e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.7490e-03,  0.0000e+00,  1.0116e-02,  ...,  0.0000e+00,\n",
      "            8.1023e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]])\n",
      "\n",
      "Upstream Grad value: tensor([[[[-2.9060e-03,  1.0559e-02, -8.7938e-03,  1.3389e-04,  3.7695e-03],\n",
      "          [-3.1380e-03,  2.0345e-03,  6.8182e-03,  1.2521e-03,  3.5134e-03],\n",
      "          [ 6.8683e-03, -2.0185e-03, -3.5710e-03,  3.3835e-04, -2.6176e-03],\n",
      "          [-9.3991e-03, -8.7406e-03, -6.6920e-03,  4.4781e-03,  6.9158e-03],\n",
      "          [ 2.0676e-03,  2.4864e-04, -2.8527e-03,  5.1401e-03,  3.9534e-03]],\n",
      "\n",
      "         [[-1.1841e-02, -1.3661e-02, -3.6758e-03, -4.0667e-03,  2.1513e-03],\n",
      "          [-3.8708e-03, -2.3883e-03, -1.0002e-02,  6.3141e-04, -1.0029e-03],\n",
      "          [-3.2328e-03,  1.2938e-02, -4.4564e-03, -2.0406e-03, -1.1572e-02],\n",
      "          [ 3.2962e-03, -5.8246e-04,  6.0511e-04,  1.0227e-02, -4.5171e-03],\n",
      "          [ 3.7465e-03,  6.0829e-04, -1.3696e-04, -6.0840e-03,  1.2648e-03]],\n",
      "\n",
      "         [[-2.0714e-03,  8.0317e-03,  7.9973e-03, -1.1685e-02,  4.3147e-03],\n",
      "          [ 3.7732e-03,  9.3004e-05,  5.7147e-03, -5.8067e-05,  2.9070e-03],\n",
      "          [ 1.1825e-03,  3.3154e-03,  1.9001e-03, -3.9784e-03, -7.5942e-03],\n",
      "          [-7.5253e-03,  1.3675e-02,  4.4039e-03,  2.6741e-04,  2.8332e-03],\n",
      "          [ 2.0035e-03,  1.0572e-02, -1.4225e-02, -8.0112e-03, -1.7121e-04]],\n",
      "\n",
      "         [[-1.0611e-03, -3.7845e-03,  5.3427e-03, -4.5300e-03, -3.5460e-03],\n",
      "          [-1.0352e-03,  4.3086e-04,  3.7659e-03,  1.9235e-03,  1.4341e-03],\n",
      "          [ 3.4882e-03, -2.1542e-04, -3.7656e-03,  1.9142e-03, -1.3448e-03],\n",
      "          [-6.3262e-03, -9.8388e-04, -1.7704e-03, -3.2271e-03,  6.6086e-03],\n",
      "          [-5.0188e-03,  4.6620e-03, -9.3363e-04,  5.7682e-04, -6.8473e-03]],\n",
      "\n",
      "         [[-9.6725e-04,  1.1055e-02,  8.9865e-03, -6.1660e-03, -2.0768e-03],\n",
      "          [-3.1314e-03,  7.7345e-03, -2.8347e-03,  1.2104e-03,  7.9365e-04],\n",
      "          [-7.4391e-03, -7.1041e-03,  1.7203e-03,  1.2020e-03,  1.0886e-02],\n",
      "          [ 2.9691e-04, -6.8398e-03,  1.2546e-02,  6.3421e-03, -8.5293e-04],\n",
      "          [ 4.0329e-03, -2.1657e-03,  9.8883e-03,  4.3965e-03,  2.1403e-03]],\n",
      "\n",
      "         [[ 1.5706e-03, -5.4497e-03,  1.7511e-03, -4.3520e-04, -8.5302e-03],\n",
      "          [ 1.1743e-02, -1.3629e-02, -6.0478e-03, -6.4585e-03, -1.6815e-03],\n",
      "          [ 1.0417e-03,  9.1686e-04, -1.8615e-03,  3.3733e-03, -2.7268e-03],\n",
      "          [ 1.4592e-03,  3.9733e-04,  1.6463e-03,  3.3402e-03,  1.5486e-03],\n",
      "          [-7.0557e-03,  5.2340e-03,  3.7695e-03, -9.7873e-03, -7.7073e-03]],\n",
      "\n",
      "         [[ 6.1070e-03,  1.7301e-03,  3.6491e-03, -2.2857e-03,  6.8348e-03],\n",
      "          [ 8.8527e-03,  1.4421e-02, -3.3077e-03, -3.0680e-03, -3.3913e-04],\n",
      "          [-2.6668e-03,  4.4887e-03, -1.0188e-02, -4.7662e-03, -2.5425e-03],\n",
      "          [-1.3493e-03, -5.1298e-03,  2.7882e-04, -4.7036e-03,  3.4948e-03],\n",
      "          [-7.4175e-03, -4.9547e-03, -1.2684e-03, -1.1850e-03,  3.4906e-03]],\n",
      "\n",
      "         [[-2.1339e-03,  9.6496e-03, -6.0892e-03, -2.0976e-03, -5.9457e-03],\n",
      "          [ 9.5987e-04, -2.0938e-03, -3.1794e-03, -9.5583e-03,  3.5858e-03],\n",
      "          [ 4.9844e-03,  6.1899e-03,  7.3592e-03, -1.2473e-03,  8.0745e-03],\n",
      "          [ 8.5451e-03, -1.6026e-03,  7.6239e-04,  2.6606e-03, -9.1689e-04],\n",
      "          [-5.9297e-04,  7.0608e-03, -7.7184e-03, -4.7432e-03,  6.6308e-04]],\n",
      "\n",
      "         [[ 3.6931e-03, -1.1673e-03, -3.0612e-03, -5.9303e-03,  2.7977e-03],\n",
      "          [-7.8508e-03,  8.0670e-04, -3.6967e-03,  4.9505e-04, -2.7247e-03],\n",
      "          [-5.3376e-03, -3.6921e-03,  1.2198e-02, -5.0991e-03, -2.3563e-03],\n",
      "          [-4.4943e-03,  1.2074e-03, -9.2379e-04,  2.6505e-03,  2.0082e-03],\n",
      "          [-1.1363e-04, -1.4052e-03,  5.5377e-03,  5.9355e-04, -3.7252e-03]],\n",
      "\n",
      "         [[ 4.7757e-03, -3.6888e-03, -1.0888e-03,  8.8817e-03,  1.7524e-03],\n",
      "          [ 5.6408e-03, -1.0132e-02,  5.3851e-03, -1.1443e-02,  6.6284e-03],\n",
      "          [ 1.0857e-02, -1.7531e-03,  6.5684e-03, -2.2384e-04, -2.5168e-03],\n",
      "          [ 3.6218e-03,  9.0249e-03, -3.8207e-03, -1.1233e-02, -1.4117e-03],\n",
      "          [ 3.2989e-04,  2.1703e-03,  1.1257e-04, -2.9075e-05, -5.9600e-05]],\n",
      "\n",
      "         [[ 1.4499e-02, -2.6213e-03,  6.9922e-04, -2.0379e-03,  2.2721e-03],\n",
      "          [ 4.9730e-03, -1.0756e-02, -5.1788e-03, -1.3307e-03, -5.9787e-03],\n",
      "          [-3.8139e-03, -2.1527e-03, -8.0109e-03, -1.2620e-04, -2.8693e-03],\n",
      "          [ 1.4513e-03, -6.4664e-03, -3.9407e-03, -4.9474e-03,  1.2650e-02],\n",
      "          [ 9.2343e-03,  5.4400e-03, -2.5482e-03,  5.5436e-03, -1.1629e-02]],\n",
      "\n",
      "         [[-7.3048e-03, -8.2513e-04,  8.4243e-03, -2.9221e-03, -6.8732e-03],\n",
      "          [-9.2054e-03, -1.9130e-03, -5.6481e-03, -2.8938e-03, -1.2616e-03],\n",
      "          [-3.9939e-03, -6.8983e-03,  5.4530e-03,  1.1459e-02, -3.4899e-03],\n",
      "          [ 3.2562e-05, -1.0743e-03,  3.6239e-03,  5.6852e-03, -2.6536e-04],\n",
      "          [ 9.4082e-04, -6.0650e-03, -5.0975e-04,  7.5616e-03,  6.3877e-03]],\n",
      "\n",
      "         [[-7.4402e-03,  8.2328e-03, -2.0259e-03,  2.3996e-03,  2.7107e-03],\n",
      "          [-3.3086e-03,  7.6437e-03, -9.8686e-03,  7.2183e-03,  1.7021e-03],\n",
      "          [-4.5042e-03,  3.3462e-04, -4.5222e-03,  5.1630e-04,  1.1772e-02],\n",
      "          [ 2.8751e-03,  6.0045e-03,  2.1268e-03,  8.1928e-04, -2.7567e-03],\n",
      "          [-3.2053e-03,  1.4058e-03,  1.7777e-04, -1.3701e-03,  2.1110e-03]],\n",
      "\n",
      "         [[ 3.9207e-03, -2.5156e-03, -4.1277e-03, -5.5947e-03, -5.2514e-03],\n",
      "          [ 1.5394e-02,  3.9897e-03,  2.0197e-03,  1.9479e-03,  2.0178e-03],\n",
      "          [-3.2966e-04, -1.1368e-03, -9.2857e-03,  3.2207e-04, -6.4664e-03],\n",
      "          [-6.1743e-03, -2.0810e-03,  7.6164e-04,  4.1604e-03,  6.2078e-03],\n",
      "          [-5.3560e-03, -4.1836e-04,  3.7218e-03, -1.8247e-03, -9.4232e-03]],\n",
      "\n",
      "         [[-5.0074e-04, -1.0326e-02,  1.4677e-05,  3.1179e-03, -7.1228e-03],\n",
      "          [-2.1819e-04,  2.5730e-04, -6.3507e-04,  7.6706e-03, -8.3796e-03],\n",
      "          [ 1.1126e-02,  6.6842e-03,  4.6398e-03, -2.0383e-03, -1.0439e-03],\n",
      "          [-6.4681e-03, -3.5709e-03,  1.8623e-02, -1.2308e-03, -3.3675e-03],\n",
      "          [ 1.5349e-03, -6.4912e-04,  1.2145e-02, -7.8270e-03,  4.3688e-03]],\n",
      "\n",
      "         [[ 1.1386e-02, -8.6323e-04, -2.8946e-03,  1.0751e-03,  5.3075e-03],\n",
      "          [-2.3051e-04, -2.5249e-03, -6.8633e-03, -6.1052e-03, -3.1486e-03],\n",
      "          [ 5.3965e-03, -7.6171e-03,  1.0026e-02,  3.9105e-03, -5.3369e-03],\n",
      "          [ 6.4746e-03, -1.1284e-02, -5.6596e-03,  6.0276e-03, -7.0775e-03],\n",
      "          [-2.7490e-03,  1.0116e-02,  9.9409e-03, -1.8770e-03,  8.1023e-03]]]])\n",
      "grad_input: torch.Size([1, 16, 10, 10]), 0.11372213065624237\n",
      "grad_output: torch.Size([1, 16, 5, 5]), 0.11372213065624237\n",
      "\n",
      "Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "---------- Incoming Gradients ----------\n",
      "\n",
      "Incoming Grad value: tensor([[[[ 9.6197e-05,  7.4683e-04,  2.3433e-04,  ..., -9.9197e-04,\n",
      "           -1.2704e-03,  3.7246e-04],\n",
      "          [ 5.3781e-05,  1.9700e-04,  2.9803e-04,  ...,  1.2186e-04,\n",
      "            1.2967e-04, -4.3618e-04],\n",
      "          [ 3.6417e-04,  1.1213e-03,  9.7843e-04,  ...,  1.0843e-03,\n",
      "           -2.4282e-04, -1.6048e-05],\n",
      "          ...,\n",
      "          [-1.9075e-04, -1.9884e-03,  1.5457e-03,  ..., -2.8447e-03,\n",
      "            1.4615e-04,  6.2480e-04],\n",
      "          [ 2.4360e-04, -4.0830e-04,  1.7287e-03,  ...,  1.3837e-03,\n",
      "            9.6786e-05, -3.3823e-04],\n",
      "          [ 0.0000e+00,  4.1868e-04, -1.2387e-03,  ..., -1.2591e-03,\n",
      "           -5.6184e-05, -4.0127e-05]],\n",
      "\n",
      "         [[ 4.2514e-04,  3.3788e-04,  1.8465e-04,  ...,  1.5865e-03,\n",
      "           -7.7272e-04, -2.8597e-04],\n",
      "          [-3.4355e-04,  1.1358e-03,  3.1086e-03,  ...,  7.2315e-04,\n",
      "           -6.9497e-04,  1.2830e-04],\n",
      "          [-5.5600e-04, -5.7967e-04, -1.2634e-03,  ...,  6.3006e-04,\n",
      "           -5.7099e-04,  7.0793e-04],\n",
      "          ...,\n",
      "          [ 2.8460e-04,  7.4489e-04,  3.5220e-04,  ..., -9.7654e-04,\n",
      "            3.1524e-04,  6.4698e-04],\n",
      "          [-2.4712e-04,  1.7514e-03,  1.2155e-03,  ...,  1.0254e-03,\n",
      "            4.6184e-05, -2.0438e-04],\n",
      "          [ 0.0000e+00,  9.3493e-04,  4.7570e-04,  ..., -3.1393e-04,\n",
      "           -1.8791e-04, -6.8397e-04]],\n",
      "\n",
      "         [[-2.9597e-04,  8.1133e-04,  4.4356e-04,  ..., -1.9421e-04,\n",
      "            3.9392e-04,  1.1919e-04],\n",
      "          [-4.2365e-04,  3.2392e-04,  4.9356e-04,  ...,  1.5971e-03,\n",
      "           -7.8068e-05, -3.5732e-04],\n",
      "          [-8.1730e-04,  8.0896e-04,  1.4004e-03,  ..., -6.4285e-04,\n",
      "           -3.0900e-04, -4.4892e-04],\n",
      "          ...,\n",
      "          [-1.0048e-03,  1.7803e-04, -8.2843e-04,  ...,  2.4602e-03,\n",
      "           -5.9857e-04,  2.3598e-04],\n",
      "          [-9.7883e-05, -3.3448e-04,  8.4390e-04,  ..., -1.2303e-03,\n",
      "            1.2855e-03,  1.7909e-04],\n",
      "          [ 0.0000e+00,  2.3385e-04,  9.5911e-04,  ..., -2.8169e-04,\n",
      "            9.3490e-04,  1.7186e-04]],\n",
      "\n",
      "         [[ 1.5424e-04, -6.6106e-04,  8.7567e-04,  ...,  5.5383e-04,\n",
      "           -4.7609e-05, -1.9470e-04],\n",
      "          [ 2.1929e-04, -5.9765e-04,  5.3133e-04,  ..., -6.6699e-05,\n",
      "            6.3207e-04,  3.8978e-04],\n",
      "          [-1.3934e-04,  4.6058e-04, -2.5750e-03,  ...,  7.3102e-04,\n",
      "            4.3491e-04,  2.9830e-04],\n",
      "          ...,\n",
      "          [ 2.4681e-04,  9.4183e-04,  3.4659e-04,  ...,  1.2213e-03,\n",
      "           -5.2823e-04, -8.0525e-04],\n",
      "          [ 1.5452e-04, -8.3775e-04,  1.6278e-03,  ..., -1.9602e-03,\n",
      "            3.8712e-04,  6.6231e-04],\n",
      "          [ 0.0000e+00,  3.2716e-04,  2.9337e-05,  ..., -1.0365e-04,\n",
      "            1.7389e-04,  3.1082e-04]],\n",
      "\n",
      "         [[-3.1893e-04,  1.0786e-03,  9.8171e-04,  ...,  1.9651e-03,\n",
      "           -1.9020e-04, -4.2883e-04],\n",
      "          [ 2.1662e-04,  6.2081e-04, -7.2906e-04,  ...,  1.1618e-03,\n",
      "           -1.4971e-03,  5.7243e-04],\n",
      "          [-5.9397e-04,  1.8722e-03,  2.0315e-03,  ...,  1.2984e-03,\n",
      "            2.9566e-04, -4.3925e-04],\n",
      "          ...,\n",
      "          [-5.3226e-05,  4.6835e-04, -6.9955e-04,  ..., -9.6415e-04,\n",
      "           -1.1878e-03, -7.5064e-04],\n",
      "          [ 3.1731e-04, -2.5283e-04,  4.6143e-05,  ...,  8.6702e-04,\n",
      "           -3.6723e-04, -6.7181e-04],\n",
      "          [ 0.0000e+00,  3.8699e-04, -1.7562e-04,  ...,  1.3025e-03,\n",
      "            6.5414e-04,  5.5585e-04]],\n",
      "\n",
      "         [[ 3.0731e-04,  6.3699e-04, -4.8456e-04,  ...,  1.3592e-03,\n",
      "           -5.7676e-04, -4.5871e-04],\n",
      "          [ 1.3272e-04, -2.9541e-04, -1.2327e-03,  ..., -2.7677e-04,\n",
      "            4.7222e-04,  7.3892e-04],\n",
      "          [ 4.6521e-04,  1.5141e-03,  2.0082e-03,  ..., -3.7802e-05,\n",
      "           -1.6622e-04,  6.7290e-04],\n",
      "          ...,\n",
      "          [-2.2998e-04, -2.2537e-04, -5.9153e-04,  ...,  1.1686e-05,\n",
      "            1.6316e-03,  1.8931e-04],\n",
      "          [-2.1600e-04, -9.2049e-04,  1.9100e-03,  ..., -8.6398e-04,\n",
      "           -5.9341e-04, -6.7842e-04],\n",
      "          [ 0.0000e+00,  5.2326e-04,  3.9358e-04,  ..., -1.1429e-04,\n",
      "            2.4077e-04, -1.0235e-03]]]])\n",
      "\n",
      "Upstream Grad value: tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.9060e-03,  0.0000e+00,  1.0559e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  3.7695e-03],\n",
      "          [-3.1380e-03,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            3.5134e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.4781e-03,\n",
      "            6.9158e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  2.0676e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  3.9534e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00, -1.1841e-02,  0.0000e+00,  ..., -4.0667e-03,\n",
      "            0.0000e+00,  2.1513e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00, -3.8708e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.7465e-03,  0.0000e+00,  0.0000e+00,  ..., -6.0840e-03,\n",
      "            1.2648e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.1685e-02,\n",
      "            0.0000e+00,  4.3147e-03],\n",
      "          [ 0.0000e+00, -2.0714e-03,  8.0317e-03,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  9.3004e-05,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  2.8332e-03],\n",
      "          [ 0.0000e+00,  2.0035e-03,  1.0572e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -8.0112e-03,\n",
      "            0.0000e+00, -1.7121e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  3.9207e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00, -5.3560e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-5.0074e-04,  0.0000e+00, -1.0326e-02,  ...,  0.0000e+00,\n",
      "           -7.1228e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00, -2.1819e-04,  0.0000e+00,  ...,  7.6706e-03,\n",
      "           -8.3796e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [-6.4681e-03,  0.0000e+00,  0.0000e+00,  ..., -1.2308e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 1.5349e-03,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            4.3688e-03,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.8270e-03,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]])\n",
      "grad_input: torch.Size([1, 6, 14, 14]), 0.05693722143769264\n",
      "grad_output: torch.Size([1, 16, 10, 10]), 0.0920804962515831\n",
      "\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "---------- Incoming Gradients ----------\n",
      "\n",
      "Incoming Grad value: tensor([[[[ 0.0000e+00,  9.6197e-05,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  3.7246e-04],\n",
      "          [ 5.3781e-05,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  2.4360e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -3.3823e-04],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -4.0127e-05],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 4.2514e-04,  0.0000e+00,  3.3788e-04,  ...,  0.0000e+00,\n",
      "           -2.8597e-04,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.7272e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-3.4355e-04,  0.0000e+00,  0.0000e+00,  ..., -6.9497e-04,\n",
      "            0.0000e+00,  1.2830e-04],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -2.4712e-04,  1.7514e-03,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.8791e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -6.8397e-04]],\n",
      "\n",
      "         [[ 0.0000e+00, -2.9597e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            1.1919e-04,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  8.1133e-04,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.2392e-04,  ..., -7.8068e-05,\n",
      "           -3.5732e-04,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  1.7186e-04],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.5424e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           -1.9470e-04,  0.0000e+00],\n",
      "          [ 0.0000e+00,  2.1929e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            3.8978e-04,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00, -8.3775e-04,  ...,  3.8712e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.2716e-04,  ...,  1.7389e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            3.1082e-04,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00, -3.1893e-04,  0.0000e+00,  ..., -1.9020e-04,\n",
      "           -4.2883e-04,  0.0000e+00],\n",
      "          [ 2.1662e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  5.7243e-04],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  3.1731e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           -6.7181e-04,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.8699e-04,  ...,  6.5414e-04,\n",
      "            0.0000e+00,  5.5585e-04]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.0731e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           -4.5871e-04,  0.0000e+00],\n",
      "          [ 1.3272e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -6.7842e-04],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.4077e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           -1.0235e-03,  0.0000e+00]]]])\n",
      "\n",
      "Upstream Grad value: tensor([[[[ 9.6197e-05,  7.4683e-04,  2.3433e-04,  ..., -9.9197e-04,\n",
      "           -1.2704e-03,  3.7246e-04],\n",
      "          [ 5.3781e-05,  1.9700e-04,  2.9803e-04,  ...,  1.2186e-04,\n",
      "            1.2967e-04, -4.3618e-04],\n",
      "          [ 3.6417e-04,  1.1213e-03,  9.7843e-04,  ...,  1.0843e-03,\n",
      "           -2.4282e-04, -1.6048e-05],\n",
      "          ...,\n",
      "          [-1.9075e-04, -1.9884e-03,  1.5457e-03,  ..., -2.8447e-03,\n",
      "            1.4615e-04,  6.2480e-04],\n",
      "          [ 2.4360e-04, -4.0830e-04,  1.7287e-03,  ...,  1.3837e-03,\n",
      "            9.6786e-05, -3.3823e-04],\n",
      "          [ 0.0000e+00,  4.1868e-04, -1.2387e-03,  ..., -1.2591e-03,\n",
      "           -5.6184e-05, -4.0127e-05]],\n",
      "\n",
      "         [[ 4.2514e-04,  3.3788e-04,  1.8465e-04,  ...,  1.5865e-03,\n",
      "           -7.7272e-04, -2.8597e-04],\n",
      "          [-3.4355e-04,  1.1358e-03,  3.1086e-03,  ...,  7.2315e-04,\n",
      "           -6.9497e-04,  1.2830e-04],\n",
      "          [-5.5600e-04, -5.7967e-04, -1.2634e-03,  ...,  6.3006e-04,\n",
      "           -5.7099e-04,  7.0793e-04],\n",
      "          ...,\n",
      "          [ 2.8460e-04,  7.4489e-04,  3.5220e-04,  ..., -9.7654e-04,\n",
      "            3.1524e-04,  6.4698e-04],\n",
      "          [-2.4712e-04,  1.7514e-03,  1.2155e-03,  ...,  1.0254e-03,\n",
      "            4.6184e-05, -2.0438e-04],\n",
      "          [ 0.0000e+00,  9.3493e-04,  4.7570e-04,  ..., -3.1393e-04,\n",
      "           -1.8791e-04, -6.8397e-04]],\n",
      "\n",
      "         [[-2.9597e-04,  8.1133e-04,  4.4356e-04,  ..., -1.9421e-04,\n",
      "            3.9392e-04,  1.1919e-04],\n",
      "          [-4.2365e-04,  3.2392e-04,  4.9356e-04,  ...,  1.5971e-03,\n",
      "           -7.8068e-05, -3.5732e-04],\n",
      "          [-8.1730e-04,  8.0896e-04,  1.4004e-03,  ..., -6.4285e-04,\n",
      "           -3.0900e-04, -4.4892e-04],\n",
      "          ...,\n",
      "          [-1.0048e-03,  1.7803e-04, -8.2843e-04,  ...,  2.4602e-03,\n",
      "           -5.9857e-04,  2.3598e-04],\n",
      "          [-9.7883e-05, -3.3448e-04,  8.4390e-04,  ..., -1.2303e-03,\n",
      "            1.2855e-03,  1.7909e-04],\n",
      "          [ 0.0000e+00,  2.3385e-04,  9.5911e-04,  ..., -2.8169e-04,\n",
      "            9.3490e-04,  1.7186e-04]],\n",
      "\n",
      "         [[ 1.5424e-04, -6.6106e-04,  8.7567e-04,  ...,  5.5383e-04,\n",
      "           -4.7609e-05, -1.9470e-04],\n",
      "          [ 2.1929e-04, -5.9765e-04,  5.3133e-04,  ..., -6.6699e-05,\n",
      "            6.3207e-04,  3.8978e-04],\n",
      "          [-1.3934e-04,  4.6058e-04, -2.5750e-03,  ...,  7.3102e-04,\n",
      "            4.3491e-04,  2.9830e-04],\n",
      "          ...,\n",
      "          [ 2.4681e-04,  9.4183e-04,  3.4659e-04,  ...,  1.2213e-03,\n",
      "           -5.2823e-04, -8.0525e-04],\n",
      "          [ 1.5452e-04, -8.3775e-04,  1.6278e-03,  ..., -1.9602e-03,\n",
      "            3.8712e-04,  6.6231e-04],\n",
      "          [ 0.0000e+00,  3.2716e-04,  2.9337e-05,  ..., -1.0365e-04,\n",
      "            1.7389e-04,  3.1082e-04]],\n",
      "\n",
      "         [[-3.1893e-04,  1.0786e-03,  9.8171e-04,  ...,  1.9651e-03,\n",
      "           -1.9020e-04, -4.2883e-04],\n",
      "          [ 2.1662e-04,  6.2081e-04, -7.2906e-04,  ...,  1.1618e-03,\n",
      "           -1.4971e-03,  5.7243e-04],\n",
      "          [-5.9397e-04,  1.8722e-03,  2.0315e-03,  ...,  1.2984e-03,\n",
      "            2.9566e-04, -4.3925e-04],\n",
      "          ...,\n",
      "          [-5.3226e-05,  4.6835e-04, -6.9955e-04,  ..., -9.6415e-04,\n",
      "           -1.1878e-03, -7.5064e-04],\n",
      "          [ 3.1731e-04, -2.5283e-04,  4.6143e-05,  ...,  8.6702e-04,\n",
      "           -3.6723e-04, -6.7181e-04],\n",
      "          [ 0.0000e+00,  3.8699e-04, -1.7562e-04,  ...,  1.3025e-03,\n",
      "            6.5414e-04,  5.5585e-04]],\n",
      "\n",
      "         [[ 3.0731e-04,  6.3699e-04, -4.8456e-04,  ...,  1.3592e-03,\n",
      "           -5.7676e-04, -4.5871e-04],\n",
      "          [ 1.3272e-04, -2.9541e-04, -1.2327e-03,  ..., -2.7677e-04,\n",
      "            4.7222e-04,  7.3892e-04],\n",
      "          [ 4.6521e-04,  1.5141e-03,  2.0082e-03,  ..., -3.7802e-05,\n",
      "           -1.6622e-04,  6.7290e-04],\n",
      "          ...,\n",
      "          [-2.2998e-04, -2.2537e-04, -5.9153e-04,  ...,  1.1686e-05,\n",
      "            1.6316e-03,  1.8931e-04],\n",
      "          [-2.1600e-04, -9.2049e-04,  1.9100e-03,  ..., -8.6398e-04,\n",
      "           -5.9341e-04, -6.7842e-04],\n",
      "          [ 0.0000e+00,  5.2326e-04,  3.9358e-04,  ..., -1.1429e-04,\n",
      "            2.4077e-04, -1.0235e-03]]]])\n",
      "grad_input: torch.Size([1, 6, 28, 28]), 0.05693722516298294\n",
      "grad_output: torch.Size([1, 6, 14, 14]), 0.05693722143769264\n",
      "\n",
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "---------- Incoming Gradients ----------\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n\u001b[1;32m     52\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# 更新参数\u001b[39;00m\n\u001b[1;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py310/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:69\u001b[0m, in \u001b[0;36m_WrappedHook.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to call the hook of a dead Module!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m, in \u001b[0;36mgrad_hook\u001b[0;34m(mod, inp, out)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Incoming Gradients \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncoming Grad value: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpstream Grad value: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(out[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# 定义一个梯度钩子函数，用于打印模块的输入和输出梯度\n",
    "def grad_hook(mod, inp, out):\n",
    "    print(\"\")\n",
    "    print(mod)\n",
    "    print(\"-\" * 10 + ' Incoming Gradients ' + '-' * 10)\n",
    "    print(\"\")\n",
    "    print('Incoming Grad value: {}'.format(inp[0].data))\n",
    "    print(\"\")\n",
    "    print('Upstream Grad value: {}'.format(out[0].data))\n",
    "    print(f\"grad_input: {inp[0].shape}, {inp[0].norm()}\")\n",
    "    print(f\"grad_output: {out[0].shape}, {out[0].norm()}\")\n",
    "    \n",
    "    \n",
    "# 创建一个简单的神经网络\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# 为每个模块注册梯度钩子\n",
    "for name, module in net.named_modules():\n",
    "    module.register_backward_hook(grad_hook)\n",
    "\n",
    "# 随机生成输入和标签\n",
    "inputs = torch.randn(1, 3, 32, 32)\n",
    "labels = torch.randint(0, 10, (1,))\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# 前向传播和反向传播\n",
    "outputs = net(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "\n",
    "# 更新参数\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6432c2-3ab8-419f-9cdc-7379d5fda70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c34daf-50aa-46bc-a2d4-8ad9f262ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8c726-1d45-40d9-88c5-2e2335bc3116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53442307-92a2-4611-a758-05dd2124a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "from peft import (\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "\n",
    "# wget -c\n",
    "\n",
    "\n",
    "class FTModel():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def from_model(self,model, peft_config=None):\n",
    "        \"\"\"\n",
    "        :param model:\n",
    "        :param peft_config:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_2_SEQ_LM,  # 任务类型 \"CAUSAL_LM\"\n",
    "            inference_mode=False,  # 是否是推理模式\n",
    "            r=8,  # 中间层神经元的个数\n",
    "            lora_alpha=32,  # 一个缩放参数\n",
    "            lora_dropout=0.1  # LoRA层的dropout率\n",
    "        )\n",
    "        peft_config = peft_config or config\n",
    "        model = get_peft_model(model, peft_config)\n",
    "        print(model.print_trainable_parameters())\n",
    "        self.model = model\n",
    "\n",
    "    def train(self,training_args, dataset):\n",
    "        from transformers import Trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset[\"train\"],  # 训练集\n",
    "            eval_dataset=dataset[\"validation\"],  # 验证集\n",
    "            # data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "            #     tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "            # ),\n",
    "        )\n",
    "\n",
    "        # 开始训练和评估模型\n",
    "        trainer.train()\n",
    "        # trainer.train#(resume_from_checkpoint=resume_from_checkpoint)\n",
    "        trainer.evaluate()\n",
    "\n",
    "    def save(self,output_dir):\n",
    "        self.model.save_pretrained(output_dir)\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class FTModel2():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def load(self,model_name,pretrained=True):\n",
    "        if model_name == 'resnet50':\n",
    "            model = models.resnet50(pretrained=pretrained)\n",
    "        return model\n",
    "\n",
    "    def freeze(self,model):\n",
    "        # 冻结\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def replace_network(self,model,class_names=10):\n",
    "        # 替换最后的全连接层，以适应新的分类任务\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def from_torchvision(self,model_name, class_names):\n",
    "        self.model = self.load(model_name=model_name)\n",
    "        self.freeze(self.model)\n",
    "        self.model = self.replace_network(self.model)\n",
    "        return self.model\n",
    "\n",
    "\n",
    "def func1(self, *_, **__):\n",
    "  return get_peft_model_state_dict(self, old_state_dict())\n",
    "model.state_dict = func1.__get__(model, type(model))\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    model = torch.compile(model)\n",
    "\n",
    "\n",
    "   model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        load_in_8bit=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=device_map,\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=lora_target_modules,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    if data_path.endswith(\".json\") or data_path.endswith(\".jsonl\"):\n",
    "        data = load_dataset(\"json\", data_files=data_path)\n",
    "    else:\n",
    "        data = load_dataset(data_path)\n",
    "\n",
    "    if resume_from_checkpoint:\n",
    "        # Check the available weights and load them\n",
    "        checkpoint_name = os.path.join(\n",
    "            resume_from_checkpoint, \"pytorch_model.bin\"\n",
    "        )  # Full checkpoint\n",
    "        if not os.path.exists(checkpoint_name):\n",
    "            checkpoint_name = os.path.join(\n",
    "                resume_from_checkpoint, \"adapter_model.bin\"\n",
    "            )  # only LoRA model - LoRA config above has to fit\n",
    "            resume_from_checkpoint = (\n",
    "                False  # So the trainer won't try loading its state\n",
    "            )\n",
    "        # The two files above have a different name depending on how they were saved, but are actually the same.\n",
    "        if os.path.exists(checkpoint_name):\n",
    "            print(f\"Restarting from {checkpoint_name}\")\n",
    "            adapters_weights = torch.load(checkpoint_name)\n",
    "            set_peft_model_state_dict(model, adapters_weights)\n",
    "        else:\n",
    "            print(f\"Checkpoint {checkpoint_name} not found\")\n",
    "\n",
    "\n",
    "# trainer\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=transformers.TrainingArguments(),\n",
    "    data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "\n",
    "\n",
    "train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "\n",
    "type(data)\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = prompter.generate_prompt(\n",
    "        data_point[\"instruction\"],\n",
    "        data_point[\"input\"],\n",
    "        data_point[\"output\"],\n",
    "    )\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    if not train_on_inputs:\n",
    "        user_prompt = prompter.generate_prompt(\n",
    "            data_point[\"instruction\"], data_point[\"input\"]\n",
    "        )\n",
    "        tokenized_user_prompt = tokenize(\n",
    "            user_prompt, add_eos_token=add_eos_token\n",
    "        )\n",
    "        user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "        if add_eos_token:\n",
    "            user_prompt_len -= 1\n",
    "\n",
    "        tokenized_full_prompt[\"labels\"] = [\n",
    "            -100\n",
    "        ] * user_prompt_len + tokenized_full_prompt[\"labels\"][\n",
    "            user_prompt_len:\n",
    "        ]  # could be sped up, probably\n",
    "    return tokenized_full_prompt\n",
    "\n",
    "    def tokenize(prompt, add_eos_token=True):\n",
    "        # there's probably a way to do this with the tokenizer settings\n",
    "        # but again, gotta move fast\n",
    "        result = tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=cutoff_len,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        if (\n",
    "            result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "            and len(result[\"input_ids\"]) < cutoff_len\n",
    "            and add_eos_token\n",
    "        ):\n",
    "            result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "            result[\"attention_mask\"].append(1)\n",
    "\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "# %load nlp_weibu/lora_train/lora_train.py\n",
    "import json\n",
    "import os.path as osp\n",
    "from typing import Union\n",
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "import fire\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "class Prompter(object):\n",
    "    __slots__ = (\"template\", \"_verbose\")\n",
    "\n",
    "    def __init__(self, template_name: str = \"\", verbose: bool = False):\n",
    "        self._verbose = verbose\n",
    "        if not template_name:\n",
    "            # Enforce the default here, so the constructor can be called with '' and will not break.\n",
    "            template_name = \"alpaca\"\n",
    "        # file_name = osp.join(\"templates\", f\"{template_name}.json\")\n",
    "        file_name = \"alpaca.json\"\n",
    "        if not osp.exists(file_name):\n",
    "            raise ValueError(f\"Can't read {file_name}\")\n",
    "        with open(file_name) as fp:\n",
    "            self.template = json.load(fp)\n",
    "        if self._verbose:\n",
    "            print(\n",
    "                f\"Using prompt template {template_name}: {self.template['description']}\"\n",
    "            )\n",
    "\n",
    "    def generate_prompt(\n",
    "        self,\n",
    "        instruction: str,\n",
    "        input: Union[None, str] = None,\n",
    "        label: Union[None, str] = None,\n",
    "    ) -> str:\n",
    "        # returns the full prompt from instruction and optional input\n",
    "        # if a label (=response, =output) is provided, it's also appended.\n",
    "        if input:\n",
    "            res = self.template[\"prompt_input\"].format(\n",
    "                instruction=instruction, input=input\n",
    "            )\n",
    "        else:\n",
    "            res = self.template[\"prompt_no_input\"].format(\n",
    "                instruction=instruction\n",
    "            )\n",
    "        if label:\n",
    "            res = f\"{res}{label}\"\n",
    "        if self._verbose:\n",
    "            print(res)\n",
    "        return res\n",
    "\n",
    "    def get_response(self, output: str) -> str:\n",
    "        return output.split(self.template[\"response_split\"])[1].strip()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Unused imports:\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "\"\"\"\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "\n",
    "def train(\n",
    "    # model/data params\n",
    "    base_model: str = \"\",  # the only required argument\n",
    "    data_path: str = \"yahma/alpaca-cleaned\",\n",
    "    output_dir: str = \"./lora-alpaca\",\n",
    "    # training hyperparams\n",
    "    batch_size: int = 128,\n",
    "    micro_batch_size: int = 4,\n",
    "    num_epochs: int = 3,\n",
    "    learning_rate: float = 3e-4,\n",
    "    cutoff_len: int = 256,\n",
    "    val_set_size: int = 2000,\n",
    "    # lora hyperparams\n",
    "    lora_r: int = 8,\n",
    "    lora_alpha: int = 16,\n",
    "    lora_dropout: float = 0.05,\n",
    "    lora_target_modules: List[str] = [\n",
    "        \"q_proj\",\n",
    "        \"v_proj\",\n",
    "    ],\n",
    "    # llm hyperparams\n",
    "    train_on_inputs: bool = True,  # if False, masks out inputs in loss\n",
    "    add_eos_token: bool = False,\n",
    "    group_by_length: bool = False,  # faster, but produces an odd training loss curve\n",
    "    # wandb params\n",
    "    wandb_project: str = \"\",\n",
    "    wandb_run_name: str = \"\",\n",
    "    wandb_watch: str = \"\",  # options: false | gradients | all\n",
    "    wandb_log_model: str = \"\",  # options: false | true\n",
    "    resume_from_checkpoint: str = None,  # either training checkpoint or final adapter\n",
    "    prompt_template_name: str = \"alpaca\",  # The prompt template to use, will default to alpaca.\n",
    "):\n",
    "    if int(os.environ.get(\"LOCAL_RANK\", 0)) == 0:\n",
    "        print(\n",
    "            f\"Training Alpaca-LoRA model with params:\\n\"\n",
    "            f\"base_model: {base_model}\\n\"\n",
    "            f\"data_path: {data_path}\\n\"\n",
    "            f\"output_dir: {output_dir}\\n\"\n",
    "            f\"batch_size: {batch_size}\\n\"\n",
    "            f\"micro_batch_size: {micro_batch_size}\\n\"\n",
    "            f\"num_epochs: {num_epochs}\\n\"\n",
    "            f\"learning_rate: {learning_rate}\\n\"\n",
    "            f\"cutoff_len: {cutoff_len}\\n\"\n",
    "            f\"val_set_size: {val_set_size}\\n\"\n",
    "            f\"lora_r: {lora_r}\\n\"\n",
    "            f\"lora_alpha: {lora_alpha}\\n\"\n",
    "            f\"lora_dropout: {lora_dropout}\\n\"\n",
    "            f\"lora_target_modules: {lora_target_modules}\\n\"\n",
    "            f\"train_on_inputs: {train_on_inputs}\\n\"\n",
    "            f\"add_eos_token: {add_eos_token}\\n\"\n",
    "            f\"group_by_length: {group_by_length}\\n\"\n",
    "            f\"wandb_project: {wandb_project}\\n\"\n",
    "            f\"wandb_run_name: {wandb_run_name}\\n\"\n",
    "            f\"wandb_watch: {wandb_watch}\\n\"\n",
    "            f\"wandb_log_model: {wandb_log_model}\\n\"\n",
    "            f\"resume_from_checkpoint: {resume_from_checkpoint or False}\\n\"\n",
    "            f\"prompt template: {prompt_template_name}\\n\"\n",
    "        )\n",
    "    assert (\n",
    "        base_model\n",
    "    ), \"Please specify a --base_model, e.g. --base_model='huggyllama/llama-7b'\"\n",
    "    gradient_accumulation_steps = batch_size // micro_batch_size\n",
    "\n",
    "    prompter = Prompter(prompt_template_name)\n",
    "    print(prompter,'prompter')\n",
    "    device_map = \"auto\"\n",
    "    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "    ddp = world_size != 1\n",
    "    if ddp:\n",
    "        device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps // world_size\n",
    "\n",
    "    # Check if parameter passed or if set within environ\n",
    "    use_wandb = len(wandb_project) > 0 or (\n",
    "        \"WANDB_PROJECT\" in os.environ and len(os.environ[\"WANDB_PROJECT\"]) > 0\n",
    "    )\n",
    "    # Only overwrite environ if wandb param passed\n",
    "    if len(wandb_project) > 0:\n",
    "        os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "    if len(wandb_watch) > 0:\n",
    "        os.environ[\"WANDB_WATCH\"] = wandb_watch\n",
    "    if len(wandb_log_model) > 0:\n",
    "        os.environ[\"WANDB_LOG_MODEL\"] = wandb_log_model\n",
    "\n",
    "    # model = LlamaForCausalLM.from_pretrained(\n",
    "    #     base_model,\n",
    "    #     load_in_8bit=True,\n",
    "    #     torch_dtype=torch.float16,\n",
    "    #     device_map=device_map,\n",
    "    # )\n",
    "\n",
    "    # tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        load_in_8bit=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=device_map,\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "\n",
    "    tokenizer.pad_token_id = (\n",
    "        0  # unk. we want this to be different from the eos token\n",
    "    )\n",
    "    tokenizer.padding_side = \"left\"  # Allow batched inference\n",
    "\n",
    "    def tokenize(prompt, add_eos_token=True):\n",
    "        # there's probably a way to do this with the tokenizer settings\n",
    "        # but again, gotta move fast\n",
    "        result = tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=cutoff_len,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        if (\n",
    "            result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "            and len(result[\"input_ids\"]) < cutoff_len\n",
    "            and add_eos_token\n",
    "        ):\n",
    "            result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "            result[\"attention_mask\"].append(1)\n",
    "\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def generate_and_tokenize_prompt(data_point):\n",
    "        full_prompt = prompter.generate_prompt(\n",
    "            data_point[\"instruction\"],\n",
    "            data_point[\"input\"],\n",
    "            data_point[\"output\"],\n",
    "        )\n",
    "        tokenized_full_prompt = tokenize(full_prompt)\n",
    "        if not train_on_inputs:\n",
    "            user_prompt = prompter.generate_prompt(\n",
    "                data_point[\"instruction\"], data_point[\"input\"]\n",
    "            )\n",
    "            tokenized_user_prompt = tokenize(\n",
    "                user_prompt, add_eos_token=add_eos_token\n",
    "            )\n",
    "            user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "            if add_eos_token:\n",
    "                user_prompt_len -= 1\n",
    "\n",
    "            tokenized_full_prompt[\"labels\"] = [\n",
    "                -100\n",
    "            ] * user_prompt_len + tokenized_full_prompt[\"labels\"][\n",
    "                user_prompt_len:\n",
    "            ]  # could be sped up, probably\n",
    "        return tokenized_full_prompt\n",
    "\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=lora_target_modules,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    if data_path.endswith(\".json\") or data_path.endswith(\".jsonl\"):\n",
    "        data = load_dataset(\"json\", data_files=data_path)\n",
    "    else:\n",
    "        data = load_dataset(data_path)\n",
    "\n",
    "    if resume_from_checkpoint:\n",
    "        # Check the available weights and load them\n",
    "        checkpoint_name = os.path.join(\n",
    "            resume_from_checkpoint, \"pytorch_model.bin\"\n",
    "        )  # Full checkpoint\n",
    "        if not os.path.exists(checkpoint_name):\n",
    "            checkpoint_name = os.path.join(\n",
    "                resume_from_checkpoint, \"adapter_model.bin\"\n",
    "            )  # only LoRA model - LoRA config above has to fit\n",
    "            resume_from_checkpoint = (\n",
    "                False  # So the trainer won't try loading its state\n",
    "            )\n",
    "        # The two files above have a different name depending on how they were saved, but are actually the same.\n",
    "        if os.path.exists(checkpoint_name):\n",
    "            print(f\"Restarting from {checkpoint_name}\")\n",
    "            adapters_weights = torch.load(checkpoint_name)\n",
    "            set_peft_model_state_dict(model, adapters_weights)\n",
    "        else:\n",
    "            print(f\"Checkpoint {checkpoint_name} not found\")\n",
    "\n",
    "    model.print_trainable_parameters()  # Be more transparent about the % of trainable params.\n",
    "\n",
    "    if val_set_size > 0:\n",
    "        train_val = data[\"train\"].train_test_split(\n",
    "            test_size=val_set_size, shuffle=True, seed=42\n",
    "        )\n",
    "        train_data = (\n",
    "            train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "        )\n",
    "        val_data = (\n",
    "            train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "        )\n",
    "    else:\n",
    "        train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "        val_data = None\n",
    "\n",
    "    if not ddp and torch.cuda.device_count() > 1:\n",
    "        # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
    "        model.is_parallelizable = True\n",
    "        model.model_parallel = True\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        args=transformers.TrainingArguments(\n",
    "            per_device_train_batch_size=micro_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "            warmup_steps=100,\n",
    "            num_train_epochs=num_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            fp16=True,\n",
    "            logging_steps=10,\n",
    "            optim=\"adamw_torch\",\n",
    "            evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n",
    "            save_strategy=\"steps\",\n",
    "            eval_steps=200 if val_set_size > 0 else None,\n",
    "            save_steps=200,\n",
    "            output_dir=output_dir,\n",
    "            save_total_limit=3,\n",
    "            load_best_model_at_end=True if val_set_size > 0 else False,\n",
    "            ddp_find_unused_parameters=False if ddp else None,\n",
    "            group_by_length=group_by_length,\n",
    "            report_to=\"wandb\" if use_wandb else None,\n",
    "            run_name=wandb_run_name if use_wandb else None,\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "            tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "        ),\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "\n",
    "    old_state_dict = model.state_dict\n",
    "    model.state_dict = (\n",
    "        lambda self, *_, **__: get_peft_model_state_dict(\n",
    "            self, old_state_dict()\n",
    "        )\n",
    "    ).__get__(model, type(model))\n",
    "\n",
    "    if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
    "\n",
    "    model.save_pretrained(output_dir)\n",
    "\n",
    "    print(\n",
    "        \"\\n If there's a warning about missing keys above, please disregard :)\"\n",
    "    )\n",
    "if __name__ == '__main__':\n",
    "    train(base_model='THUDM/chatglm2-6b',\n",
    "          data_path='yahma/alpaca-cleaned',\n",
    "          output_dir='./lora-alpaca',\n",
    "          batch_size=128,\n",
    "          )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!pip\n",
    "install\n",
    "transformers\n",
    "!pip\n",
    "install\n",
    "peft\n",
    "\n",
    "# 导入所需的模块和配置类\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# 选择一个预训练的模型和分词器\n",
    "model_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "\n",
    "# 设置LoRA的配置参数\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,  # 任务类型\n",
    "    inference_mode=False,  # 是否是推理模式\n",
    "    r=8,  # 中间层神经元的个数\n",
    "    lora_alpha=32,  # 一个缩放参数\n",
    "    lora_dropout=0.1  # LoRA层的dropout率\n",
    ")\n",
    "\n",
    "# 用预训练的模型初始化一个序列到序列模型类\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "\n",
    "# 用get_peft_model函数将LoRA方法应用到模型上\n",
    "model = get_peft_model(model, peft_config)\n",
    "print(123)\n",
    "# 打印出可训练的参数数量和比例\n",
    "model.print_trainable_parameters()\n",
    "# output: trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282\n",
    "\n",
    "# 用常规的PyTorch或HuggingFace Trainer API来训练模型\n",
    "# 省略训练代码...\n",
    "\n",
    "\n",
    "Downloading(…)lve / main / config.json: 0 % | | 0.00 / 800[00:00 <?, ?B / s]\n",
    "Downloading\n",
    "pytorch_model.bin: 0 % | | 0.00 / 4.92\n",
    "G[00:00 <?, ?B / s]\n",
    "123\n",
    "trainable\n",
    "params: 2359296 | | all\n",
    "params: 1231940608 | | trainable %: 0.19151053100118282\n",
    "成功\n",
    "\n",
    "# 导入所需的模块\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 选择一个分词器\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)\n",
    "\n",
    "# 加载或创建您的数据集\n",
    "dataset = load_dataset(\"path/to/your/data\")\n",
    "\n",
    "\n",
    "# 或者\n",
    "# dataset = Dataset.from_dict(your_data)\n",
    "\n",
    "# 定义一个分词函数\n",
    "def tokenize_dataset(data):\n",
    "    # Keys of the returned dictionary will be added to the dataset as columns\n",
    "    return tokenizer(data[\"text\"])\n",
    "\n",
    "\n",
    "# 对数据集进行分词\n",
    "dataset = dataset.map(tokenize_dataset)\n",
    "\n",
    "\n",
    "\n",
    "!pip\n",
    "install\n",
    "datasets\n",
    "\n",
    "# 导入所需的模块\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 选择一个分词器\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)\n",
    "\n",
    "\n",
    "# 定义一个分词函数\n",
    "def tokenize_dataset(data):\n",
    "    # Keys of the returned dictionary will be added to the dataset as columns\n",
    "    return tokenizer(data[\"text\"])\n",
    "\n",
    "\n",
    "Downloading(…)okenizer_config.json: 0 % | | 0.00 / 430[00:00 <?, ?B / s]\n",
    "Downloading\n",
    "spiece.model: 0 % | | 0.00 / 4.31\n",
    "M[00:00 <?, ?B / s]\n",
    "Downloading\n",
    "tokenizer.json: 0 % | | 0.00 / 16.3\n",
    "M[00:00 <?, ?B / s]\n",
    "Downloading(…)cial_tokens_map.json: 0 % | | 0.00 / 74.0[00:00 <?, ?B / s]\n",
    "\n",
    "# 导入所需的模块和配置类\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# 选择一个预训练的模型和分词器\n",
    "model_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "\n",
    "# 设置LoRA的配置参数\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,  # 任务类型\n",
    "    inference_mode=False,  # 是否是推理模式\n",
    "    r=8,  # 中间层神经元的个数\n",
    "    lora_alpha=32,  # 一个缩放参数\n",
    "    lora_dropout=0.1  # LoRA层的dropout率\n",
    ")\n",
    "\n",
    "# 用预训练的模型初始化一个序列到序列模型类\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "\n",
    "# 用get_peft_model函数将LoRA方法应用到模型上\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # 输出目录\n",
    "    num_train_epochs=3,  # 训练轮数\n",
    "    per_device_train_batch_size=16,  # 每个设备上的训练批次大小\n",
    "    per_device_eval_batch_size=16,  # 每个设备上的评估批次大小\n",
    "    warmup_steps=500,  # 热身步数\n",
    "    weight_decay=0.01,  # 权重衰减率\n",
    "    logging_dir=\"./logs\",  # 日志目录\n",
    "    logging_steps=10,  # 记录日志的步数间隔\n",
    ")\n",
    "\n",
    "# 加载或创建您的数据集，这里我们直接从网上加载一个文本生成数据集[^2^][2]\n",
    "dataset = load_dataset(\"totto\")\n",
    "\n",
    "\n",
    "# 定义一个分词函数\n",
    "def tokenize_dataset(data):\n",
    "    # Keys of the returned dictionary will be added to the dataset as columns\n",
    "    return tokenizer(data[\"text\"])\n",
    "\n",
    "\n",
    "# 对数据集进行分词\n",
    "dataset = dataset.map(tokenize_dataset)\n",
    "\n",
    "# 创建一个Trainer类实例，并传入模型，训练参数和数据集\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],  # 训练集\n",
    "    eval_dataset=dataset[\"validation\"],  # 验证集\n",
    ")\n",
    "\n",
    "# 开始训练和评估模型\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "\n",
    "WARNING: datasets.builder:Found\n",
    "cached\n",
    "dataset\n",
    "totto( / root /.cache / huggingface / datasets / totto / default / 1.0\n",
    ".0 / 263\n",
    "c85871e5451bc892c65ca0306c0629eb7beb161e0eb998f56231562335dd2)\n",
    "0 % | | 0 / 3[00:00 <?, ?it / s]\n",
    "Map: 0 % | | 0 / 120761[00:00 <?, ? examples / s]\n",
    "╭─────────────────────────────── Traceback(most\n",
    "recent\n",
    "call\n",
    "last) ────────────────────────────────╮\n",
    "│ in < cell\n",
    "line: 46 >:46                                                                            │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / datasets / dataset_dict.py: 851 in map                      │\n",
    "│                                                                                                  │\n",
    "│    848 │   │   if cache_file_names is None:                                                      │\n",
    "│    849 │   │   │   cache_file_names = {k: None for k in self}                                    │\n",
    "│    850 │   │   return DatasetDict(                                                               │\n",
    "│ ❱  851 │   │   │   {                                                                             │\n",
    "│    852 │   │   │   │   k: dataset.map(                                                           │\n",
    "│    853 │   │   │   │   │   function = function,                                                    │\n",
    "│    854 │   │   │   │   │   with_indices = with_indices,                                            │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / datasets / dataset_dict.py: 852 in < dictcomp >               │\n",
    "│                                                                                                  │\n",
    "│    849 │   │   │   cache_file_names = {k: None for k in self}                                    │\n",
    "│    850 │   │   return DatasetDict(                                                               │\n",
    "│    851 │   │   │   {                                                                             │\n",
    "│ ❱  852 │   │   │   │   k: dataset.map(                                                           │\n",
    "│    853 │   │   │   │   │   function = function,                                                    │\n",
    "│    854 │   │   │   │   │   with_indices = with_indices,                                            │\n",
    "│    855 │   │   │   │   │   with_rank = with_rank,                                                  │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / datasets / arrow_dataset.py: 578 in wrapper                 │\n",
    "│                                                                                                  │\n",
    "│    575 │   │ else:                                                                             │\n",
    "│    576 │   │   │   self: \"Dataset\" = kwargs.pop(\"self\")                                          │\n",
    "│    577 │   │  # apply actual function                                                           │\n",
    "│ ❱  578 │   │   out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)                │\n",
    "│    579 │   │   datasets: List[\"Dataset\"] = list(out.values()) if isinstance(out, dict) else [ou  │\n",
    "│    580 │   │   for dataset in datasets:                                                          │\n",
    "│    581 │   │   │  # Remove task templates if a column mapping of the template is no longer val  │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / datasets / arrow_dataset.py: 543 in wrapper                 │\n",
    "│                                                                                                  │\n",
    "│    540 │   │   │   \"output_all_columns\": self._output_all_columns, │\n",
    "│    541 │   │}                                                                                 │\n",
    "│    542 │   │  # apply actual function                                                           │\n",
    "│ ❱  543 │   │   out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)                │\n",
    "│    544 │   │   datasets: List[\"Dataset\"] = list(out.values()) if isinstance(out, dict) else [ou  │\n",
    "│    545 │   │  # re-apply format to the output                                                   │\n",
    "│    546 │   │   for dataset in datasets:                                                          │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / datasets / arrow_dataset.py: 3073 in map                    │\n",
    "│                                                                                                  │\n",
    "│   3070 │   │   │   │   │   leave = False,                                                          │\n",
    "│   3071 │   │   │   │   │   desc = desc or \"Map\",                                                   │\n",
    "│   3072 │   │   │   │   ) as pbar:                                                                │\n",
    "│ ❱ 3073 │   │   │   │   │   for rank, done, content in Dataset._map_single(**dataset_kwargs):     │\n",
    "│   3074 │   │   │   │   │   │   if done:                                                          │\n",
    "│   3075 │   │   │   │   │   │   │   shards_done += 1                                              │\n",
    "│   3076 │   │   │   │   │   │   │   logger.debug(f\"Finished processing shard number {rank} of {n  │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / datasets / arrow_dataset.py: 3427 in _map_single            │\n",
    "│                                                                                                  │\n",
    "│   3424 │   │   │   │   if not batched:                                                           │\n",
    "│   3425 │   │   │   │   │   _time = time.time()                                                   │\n",
    "│   3426 │   │   │   │   │   for i, example in shard_iterable:                                     │\n",
    "│ ❱ 3427 │   │   │   │   │   │   example = apply_function_on_filtered_inputs(example, i, offset=o  │\n",
    "│   3428 │   │   │   │   │   │   if update_data:                                                   │\n",
    "│   3429 │   │   │   │   │   │   │   if i == 0:                                                    │\n",
    "│   3430 │   │   │   │   │   │   │   │   buf_writer, writer, tmp_file = init_buffer_and_writer()   │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / datasets / arrow_dataset.py: 3330 in                        │\n",
    "│ apply_function_on_filtered_inputs                                                                │\n",
    "│                                                                                                  │\n",
    "│   3327 │   │   │   │   additional_args += (effective_indices,)                                   │\n",
    "│   3328 │   │   │   if with_rank:                                                                 │\n",
    "│   3329 │   │   │   │   additional_args += (rank,)                                                │\n",
    "│ ❱ 3330 │   │   │   processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)          │\n",
    "│   3331 │   │   │   if isinstance(processed_inputs, LazyDict):                                    │\n",
    "│   3332 │   │   │   │   processed_inputs = {                                                      │\n",
    "│   3333 │   │   │   │   │   k: v\n",
    "for k, v in processed_inputs.data.items() if k not in processed  │\n",
    "│ in tokenize_dataset:43                                                                           │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / datasets / formatting / formatting.py: 270 in __getitem__     │\n",
    "│                                                                                                  │\n",
    "│   267 │   │   return len(self.data)                                                              │\n",
    "│   268 │                                                                                          │\n",
    "│   269 │\n",
    "\n",
    "def __getitem__(self, key):                                                            │\n",
    "\n",
    "│ ❱ 270 │   │   value = self.data[key]                                                             │\n",
    "│   271 │   │   if key in self.keys_to_format:                                                     │\n",
    "│   272 │   │   │   value = self.format(key)                                                       │\n",
    "│   273 │   │   │   self.data[key] = value                                                         │\n",
    "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
    "KeyError: 'text'\n",
    "\n",
    "# final\n",
    "\n",
    "# 导入所需的模块和配置类\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments, AutoTokenizer\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# 选择一个预训练的模型和分词器\n",
    "model_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "\n",
    "# 设置LoRA的配置参数\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,  # 任务类型\n",
    "    inference_mode=False,  # 是否是推理模式\n",
    "    r=8,  # 中间层神经元的个数\n",
    "    lora_alpha=32,  # 一个缩放参数\n",
    "    lora_dropout=0.1  # LoRA层的dropout率\n",
    ")\n",
    "\n",
    "# 用预训练的模型初始化一个序列到序列模型类\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "\n",
    "# 用get_peft_model函数将LoRA方法应用到模型上\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # 输出目录\n",
    "    num_train_epochs=3,  # 训练轮数\n",
    "    per_device_train_batch_size=16,  # 每个设备上的训练批次大小\n",
    "    per_device_eval_batch_size=16,  # 每个设备上的评估批次大小\n",
    "    warmup_steps=500,  # 热身步数\n",
    "    weight_decay=0.01,  # 权重衰减率\n",
    "    logging_dir=\"./logs\",  # 日志目录\n",
    "    logging_steps=10,  # 记录日志的步数间隔\n",
    ")\n",
    "\n",
    "# 加载或创建您的数据集，这里我们直接从网上加载一个文本生成数据集\n",
    "dataset = load_dataset(\"totto\")\n",
    "\n",
    "WARNING: datasets.builder:Found\n",
    "cached\n",
    "dataset\n",
    "totto( / root /.cache / huggingface / datasets / totto / default / 1.0\n",
    ".0 / 263\n",
    "c85871e5451bc892c65ca0306c0629eb7beb161e0eb998f56231562335dd2)\n",
    "0 % | | 0 / 3[00:00 <?, ?it / s]\n",
    "\n",
    "dataset.keys()\n",
    "\n",
    "dict_keys(['train', 'validation', 'test'])\n",
    "\n",
    "dataset['train']\n",
    "\n",
    "Dataset({\n",
    "    features: ['id', 'table_page_title', 'table_webpage_url', 'table_section_title', 'table_section_text', 'table',\n",
    "               'highlighted_cells', 'example_id', 'sentence_annotations', 'overlap_subset'],\n",
    "    num_rows: 120761\n",
    "})\n",
    "\n",
    "\n",
    "# 定义一个分词函数，注意修改键名为\"sentence_annotations\"，以匹配数据集的格式\n",
    "# 并且从字典中选择\"final_sentence\"作为文本数据\n",
    "# def tokenize_dataset(data):\n",
    "#     # print(data,'data')\n",
    "#     # Keys of the returned dictionary will be added to the dataset as columns\n",
    "#     return tokenizer(data[\"sentence_annotations\"][\"final_sentence\"])\n",
    "\n",
    "def tokenize_dataset(data):\n",
    "    # Keys of the returned dictionary will be added to the dataset as columns\n",
    "    return tokenizer(data[\"sentence_annotations\"][\"final_sentence\"], truncation=True)\n",
    "\n",
    "\n",
    "# 创建一个分词器对象\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)\n",
    "\n",
    "# 定义一个分词函数，注意修改键名为\"final_sentence\"，以匹配数据集的格式\n",
    "# def tokenize_dataset(data):\n",
    "#     # Keys of the returned dictionary will be added to the dataset as columns\n",
    "#     return tokenizer(data[\"sentence_annotations\"])\n",
    "\n",
    "# 对数据集进行分词\n",
    "dataset = dataset.map(tokenize_dataset)\n",
    "\n",
    "# 创建一个Trainer类实例，并传入模型，训练参数和数据集\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],  # 训练集\n",
    "    eval_dataset=dataset[\"validation\"],  # 验证集\n",
    ")\n",
    "\n",
    "# 开始训练和评估模型\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "\n",
    "Map: 0 % | | 0 / 120761[00:00 <?, ? examples / s]\n",
    "Asking\n",
    "to\n",
    "truncate\n",
    "to\n",
    "max_length\n",
    "but\n",
    "no\n",
    "maximum\n",
    "length is provided and the\n",
    "model\n",
    "has\n",
    "no\n",
    "predefined\n",
    "maximum\n",
    "length.Default\n",
    "to\n",
    "no\n",
    "truncation.\n",
    "Map: 0 % | | 0 / 7700[00:00 <?, ? examples / s]\n",
    "Map: 0 % | | 0 / 7700[00:00 <?, ? examples / s]\n",
    "╭─────────────────────────────── Traceback(most\n",
    "recent\n",
    "call\n",
    "last) ────────────────────────────────╮\n",
    "│ in < cell\n",
    "line: 21 >:21                                                                            │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / transformers / trainer.py: 1664 in train                    │\n",
    "│                                                                                                  │\n",
    "│   1661 │   │   inner_training_loop = find_executable_batch_size(                                 │\n",
    "│   1662 │   │   │   self._inner_training_loop, self._train_batch_size, args.auto_find_batch_size  │\n",
    "│   1663 │   │   )                                                                                 │\n",
    "│ ❱ 1664 │   │   return inner_training_loop(                                                       │\n",
    "│   1665 │   │   │   args = args,                                                                    │\n",
    "│   1666 │   │   │   resume_from_checkpoint = resume_from_checkpoint,                                │\n",
    "│   1667 │   │   │   trial = trial,                                                                  │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / transformers / trainer.py: 1909 in _inner_training_loop     │\n",
    "│                                                                                                  │\n",
    "│   1906 │   │   │   │   rng_to_sync = True                                                        │\n",
    "│   1907 │   │   │                                                                                 │\n",
    "│   1908 │   │   │   step = -1                                                                     │\n",
    "│ ❱ 1909 │   │   │   for step, inputs in enumerate(epoch_iterator):                                │\n",
    "│   1910 │   │   │   │   total_batched_samples += 1                                                │\n",
    "│   1911 │   │   │   │   if rng_to_sync:                                                           │\n",
    "│   1912 │   │   │   │   │   self._load_rng_state(resume_from_checkpoint)                          │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / torch / utils / data / dataloader.py: 634 in __next__           │\n",
    "│                                                                                                  │\n",
    "│    631 │   │   │   if self._sampler_iter is None:                                                │\n",
    "│    632 │   │   │   │  # TODO(https://github.com/pytorch/pytorch/issues/76750)                   │\n",
    "│    633 │   │   │   │   self._reset()  # type: ignore[call-arg]                                   │\n",
    "│ ❱  634 │   │   │   data = self._next_data()                                                      │\n",
    "│    635 │   │   │   self._num_yielded += 1                                                        │\n",
    "│    636 │   │   │   if self._dataset_kind == _DatasetKind.Iterable and \\                          │\n",
    "│    637 │   │   │   │   │   self._IterableDataset_len_called is not None and  \\                    │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3.10 / dist-packages / torch / utils / data / dataloader.py:678 in _next_data         │\n",
    "│                                                                                                  │\n",
    "│    675 │                                                                                         │\n",
    "│    676 │\n",
    "\n",
    "def _next_data(self):                                                                 │\n",
    "\n",
    "│    677 │   │   index = self._next_index()  # may raise StopIteration                             │\n",
    "│ ❱  678 │   │   data = self._dataset_fetcher.fetch(index)  # may raise StopIteration              │\n",
    "│    679 │   │   if self._pin_memory:                                                              │\n",
    "│    680 │   │   │   data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)            │\n",
    "│    681 │   │   return data                                                                       │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / torch / utils / data / _utils / fetch.py: 54 in fetch             │\n",
    "│                                                                                                  │\n",
    "│   51 │   │   │   │   data = [self.dataset[idx] for idx in possibly_batched_index]                │\n",
    "│   52 │   │ else:                                                                               │\n",
    "│   53 │   │   │   data = self.dataset[possibly_batched_index]                                     │\n",
    "│ ❱ 54 │   │   return self.collate_fn(data)                                                        │\n",
    "│   55                                                                                             │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / transformers / data / data_collator.py: 70 in                 │\n",
    "│ default_data_collator                                                                            │\n",
    "│                                                                                                  │\n",
    "│     67 │  # on the whole batch.                                                                 │\n",
    "│     68 │                                                                                         │\n",
    "│     69 │   if return_tensors == \"pt\":                                                            │\n",
    "│ ❱   70 │   │   return torch_default_data_collator(features)                                      │\n",
    "│     71 │ elif return_tensors == \"tf\":                                                          │\n",
    "│     72 │   │   return tf_default_data_collator(features)                                         │\n",
    "│     73 │ elif return_tensors == \"np\":                                                          │\n",
    "│                                                                                                  │\n",
    "│ / usr / local / lib / python3\n",
    ".10 / dist - packages / transformers / data / data_collator.py: 136 in                │\n",
    "│ torch_default_data_collator                                                                      │\n",
    "│                                                                                                  │\n",
    "│    133 │   │   │ elif isinstance(v, np.ndarray):                                               │\n",
    "│    134 │   │   │   │   batch[k] = torch.tensor(np.stack([f[k] for f in features]))               │\n",
    "│    135 │   │   │ else:                                                                         │\n",
    "│ ❱  136 │   │   │   │   batch[k] = torch.tensor([f[k] for f in features])                         │\n",
    "│    137 │                                                                                         │\n",
    "│    138 │   return batch                                                                          │\n",
    "│    139                                                                                           │\n",
    "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
    "ValueError: expected\n",
    "sequence\n",
    "of\n",
    "length\n",
    "25\n",
    "at\n",
    "dim\n",
    "2(got\n",
    "28)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# final\n",
    "\n",
    "# 导入所需的模块和配置类\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments, AutoTokenizer\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# 选择一个预训练的模型和分词器\n",
    "model_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "\n",
    "# 设置LoRA的配置参数\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,  # 任务类型\n",
    "    inference_mode=False,  # 是否是推理模式\n",
    "    r=8,  # 中间层神经元的个数\n",
    "    lora_alpha=32,  # 一个缩放参数\n",
    "    lora_dropout=0.1  # LoRA层的dropout率\n",
    ")\n",
    "\n",
    "# 用预训练的模型初始化一个序列到序列模型类\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "\n",
    "# 用get_peft_model函数将LoRA方法应用到模型上\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # 输出目录\n",
    "    num_train_epochs=3,  # 训练轮数\n",
    "    per_device_train_batch_size=16,  # 每个设备上的训练批次大小\n",
    "    per_device_eval_batch_size=16,  # 每个设备上的评估批次大小\n",
    "    warmup_steps=500,  # 热身步数\n",
    "    weight_decay=0.01,  # 权重衰减率\n",
    "    logging_dir=\"./logs\",  # 日志目录\n",
    "    logging_steps=10,  # 记录日志的步数间隔\n",
    ")\n",
    "\n",
    "# 加载或创建您的数据集，这里我们直接从网上加载一个文本生成数据集\n",
    "dataset = load_dataset(\"totto\")\n",
    "\n",
    "\n",
    "def tokenize_dataset(data):\n",
    "    # Keys of the returned dictionary will be added to the dataset as columns\n",
    "    return tokenizer(data[\"sentence_annotations\"][\"final_sentence\"], truncation=True)\n",
    "\n",
    "\n",
    "# 创建一个分词器对象\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)\n",
    "\n",
    "# 定义一个分词函数，注意修改键名为\"final_sentence\"，以匹配数据集的格式\n",
    "# def tokenize_dataset(data):\n",
    "#     # Keys of the returned dictionary will be added to the dataset as columns\n",
    "#     return tokenizer(data[\"sentence_annotations\"])\n",
    "\n",
    "# 对数据集进行分词\n",
    "dataset = dataset.map(tokenize_dataset)\n",
    "\n",
    "# 创建一个Trainer类实例，并传入模型，训练参数和数据集\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],  # 训练集\n",
    "    eval_dataset=dataset[\"validation\"],  # 验证集\n",
    ")\n",
    "\n",
    "# 开始训练和评估模型\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "\n",
    "ValueError: expected\n",
    "sequence\n",
    "of\n",
    "length\n",
    "25\n",
    "at\n",
    "dim\n",
    "2(got\n",
    "28)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 导入所需的模块和配置类\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments, AutoTokenizer\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# 选择一个预训练的模型和分词器\n",
    "model_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "\n",
    "# 设置LoRA的配置参数\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,  # 任务类型\n",
    "    inference_mode=False,  # 是否是推理模式\n",
    "    r=8,  # 中间层神经元的个数\n",
    "    lora_alpha=32,  # 一个缩放参数\n",
    "    lora_dropout=0.1  # LoRA层的dropout率\n",
    ")\n",
    "\n",
    "# 用预训练的模型初始化一个序列到序列模型类\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "\n",
    "# 用get_peft_model函数将LoRA方法应用到模型上\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # 输出目录\n",
    "    num_train_epochs=3,  # 训练轮数\n",
    "    per_device_train_batch_size=16,  # 每个设备上的训练批次大小\n",
    "    per_device_eval_batch_size=16,  # 每个设备上的评估批次大小\n",
    "    warmup_steps=500,  # 热身步数\n",
    "    weight_decay=0.01,  # 权重衰减率\n",
    "    logging_dir=\"./logs\",  # 日志目录\n",
    "    logging_steps=10,  # 记录日志的步数间隔\n",
    ")\n",
    "\n",
    "# 加载或创建您的数据集，这里我们直接从网上加载一个文本生成数据集\n",
    "dataset = load_dataset(\"totto\")\n",
    "\n",
    "\n",
    "# 定义一个分词函数，注意修改键名为\"sentence_annotations\"，以匹配数据集的格式\n",
    "# 并且从字典中选择\"final_sentence\"作为文本数据\n",
    "# 并且添加一个参数，将文本截断到模型的最大长度\n",
    "\n",
    "# def tokenize_dataset(data):\n",
    "#     # Keys of the returned dictionary will be added to the dataset as columns\n",
    "#     return tokenizer(data[\"sentence_annotations\"][\"final_sentence\"], truncation=True)\n",
    "\n",
    "def tokenize_dataset(data, tokenizer):\n",
    "    # Keys of the returned dictionary will be added to the dataset as columns\n",
    "    return tokenizer(data[\"sentence_annotations\"][\"final_sentence\"], truncation=True)\n",
    "\n",
    "\n",
    "# 创建一个分词器对象，并传入分词函数中作为参数\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)\n",
    "dataset = dataset.map(lambda x: tokenize_dataset(x, tokenizer))\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)\n",
    "# dataset = dataset.map(lambda x: tokenize_dataset(x, tokenizer))\n",
    "\n",
    "# 创建一个Trainer类实例，并传入模型，训练参数和数据集\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],  # 训练集\n",
    "    eval_dataset=dataset[\"validation\"],  # 验证集\n",
    ")\n",
    "\n",
    "# 开始训练和评估模型\n",
    "trainer.train()\n",
    "trainer.evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
