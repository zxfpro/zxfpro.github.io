{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11253c9-0ade-4c97-85be-28c4d82c0121",
   "metadata": {},
   "source": [
    "# IndexMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0486d916-a53a-4a0c-b6a0-239382b4168b",
   "metadata": {},
   "source": [
    "## Document -> index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8587624-67d0-4f87-8593-cf162fed4998",
   "metadata": {
    "tags": []
   },
   "source": [
    "这一层是将transformers + index 作为一个完整结构    \n",
    "如何处理好最全最好的数据 建立最合理的标签和关系    \n",
    "也是数据打标记的关键时间    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2e260-2f2a-441d-bafd-b83672191bc4",
   "metadata": {},
   "source": [
    "## splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6884cf0-596a-42b9-83ff-561edb01021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from zxftools.rag import SplitterFactory,SplitterType\n",
    "from zxftools.rag import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590be19-5581-4238-86f0-726fc12fe687",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './paul_graham_essay.txt'\n",
    "documents = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229e76e-58f8-4fdd-a82c-59dc448be32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SplitterFactory(SplitterType.SENTENCE)\n",
    "nodes = splitter.get_nodes_from_documents(self.documents)\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de50576-0849-424a-9d6f-751779ef13ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11185ea8-279c-4dd9-970a-3b153363ac30",
   "metadata": {},
   "source": [
    "## Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4934352c-84c0-48a0-841f-a5d42a3277a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zxftools_dev.rag import ExtractorFactory,ExtractorType\n",
    "\n",
    "from llama_index.core.schema import Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26202e21-13fb-458c-a367-842b7e84b3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qet import get_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d944d48-92f8-4d18-a416-f890685bc8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodes = [Node(text='这是一个测试'), Node(text='这是一个demo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ef56c5f-6b5e-4ec5-b260-fefa16e2560b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8f11ed4-3a59-42cd-b2eb-52a6ddd081ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extra = ExtractorFactory(ExtractorType.TITLE,llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d51b5a2f-45d1-4e62-a114-02fbb2fff22b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "result = extra.extract(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfb51a-f7f7-4d4b-b949-b7c749c5b9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8efb25ed-3686-4aef-a545-e574d8b65016",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a78601-fdea-4f27-9744-931b22ad1521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f74f54-75cd-45c9-8655-563cf20b8475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2038b0-520a-402b-bb1b-2527c473d188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b0a79-6b1f-4030-90b6-57d165901999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432de9e-94f6-4d18-b319-cbc01ec2316b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ff3c9-4e8d-40e3-b96d-8ee7db8e636f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea4264-486f-43ec-a835-4a9680a391d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e088f-d79a-4935-b350-3fe5481594f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f6617-2a07-42af-a44d-db39d5fe7ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd9fb1-5923-4097-aa57-d16c32ecece1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65eeadc2-58d9-4be3-9b4c-bd88d9bc95a1",
   "metadata": {},
   "source": [
    "### node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551c76f-34c4-49f5-a08c-dc3a62b20ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[21].get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8679f-b7d5-4be2-b944-0b73535a0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 text 构建Node\n",
    "from llama_index.core.schema import TextNode\n",
    "node1 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bccd45-7a7e-4c3a-93cf-cad4c03162c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_1[3].get_content(metadata_mode=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900f256-43d3-44b5-b87e-ad76b3dd9ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00a40896-e8ec-4ad8-85c8-9c907cbcaa30",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 快速IngestionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb02a9-4590-49eb-ad91-c3fdecbf6349",
   "metadata": {},
   "source": [
    "上述实验的结果在下面重新共享，每个策略都用这个示例数据集和管道从最快到最慢列出。\n",
    "\n",
    "（异步、并行处理）：20.3s    \n",
    "（异步，无并行处理）：20.5s    \n",
    "（同步，并行处理）：29s    \n",
    "（同步，无并行处理）：1分钟11s    \n",
    "我们可以看到，使用并行处理的两种情况都优于同步，无并行处理（即.run(num_workers=None)）。此外，至少对于异步任务来说，使用并行处理几乎没有好处。也许对于更大的工作负载和IngestionPipelines，使用Async与并行处理可以带来更大的收益。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2149f8-3b40-47cd-8b25-011412e8a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ab36e-98f5-45c1-bedd-9bab797e491f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5e364-db2c-4611-9b08-2f7a417ef8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc24f7b-ca74-4d4f-9c3a-269c996d1561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d23180-7fd2-44c0-82cc-e972f6eca865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610b779-38e1-4ac9-92a0-271a714ae302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bd5d6-634c-419e-9442-045b7a93e1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419aaec-f2a8-479e-85a2-be689230c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE 的存储 /redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0717cc-28f6-4654-9b66-0c27620ae026",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = IngestionPipeline(transformations=transformations)\n",
    "\n",
    "nodes = pipeline.run(documents=documents)\n",
    "from llama_index.core.question_gen.prompts import (\n",
    "    DEFAULT_SUB_QUESTION_PROMPT_TMPL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3291d7d-9365-457d-b0d9-5fdfb92ea6cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601d241-189b-48e8-8414-3438bae9c337",
   "metadata": {},
   "source": [
    "没什么特殊的,只有前后关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc126c26-031a-49f2-86ff-3f0cdcd01562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n",
    "\n",
    "node1 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\n",
    "node2 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\n",
    "# set relationships\n",
    "node1.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n",
    "    node_id=node2.node_id\n",
    ")\n",
    "node2.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n",
    "    node_id=node1.node_id\n",
    ")\n",
    "nodes = [node1, node2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a6219-ff7d-4297-82ba-19e30b972daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n",
    "    node_id=node1.node_id, metadata={\"key\": \"val\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e1701-ffa6-495b-aa56-0782b5ab9453",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 由documents 列表构建 VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ed22d28-3c36-4c6f-8ea6-1f2011d771af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "text_list = ['你好', '我爱爱你我爱你我爱你', '骑爱你']\n",
    "documents = [Document(text=t) for t in text_list]\n",
    "\n",
    "# build index\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "# 指定text_splitter\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, transformations=[text_splitter]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23524fce-c43c-40e7-832c-6d72bfe4ff0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 由nodes 列表构建 VectorStoreIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791fa6d-389d-454d-9c65-36c1b31291ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Document -> index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7245192a-3ec0-49ef-bd3f-f77b6079c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056074d-3393-4758-b840-154b6a571d59",
   "metadata": {
    "tags": []
   },
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "03427cb2-8970-4fa2-8cb8-937a3cf7052c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.embeddings.fastembed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastembed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastEmbedEmbedding\n\u001b[1;32m      3\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m FastEmbedEmbedding(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBAAI/bge-small-en-v1.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.embeddings.fastembed'"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71b38f0a-f365-459f-8892-4fbe28641cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "[-0.020769083872437477, 0.005072064232081175, -0.0033557764254510403, -0.010965541936457157, 0.009616553783416748]\n"
     ]
    }
   ],
   "source": [
    "embeddings = embed_model.get_text_embedding(\"Some text to embed.\")\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31cea63-5000-4602-89d3-33f94c3bc95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.text_embeddings_inference import (\n",
    "    TextEmbeddingsInference,\n",
    ")\n",
    "\n",
    "\n",
    "embed_model = TextEmbeddingsInference(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\",  # required for formatting inference text,\n",
    "    timeout=60,  # timeout in seconds\n",
    "    embed_batch_size=10,  # batch size for embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1086ca-caa7-4a04-826c-135546da12f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = embed_model.get_text_embedding(\"Hello World!\")\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3f848-6a11-4cc4-9624-5f9f39a51947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = await embed_model.aget_text_embedding(\"Hello World!\")\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d7fdac-f0f8-46a6-b004-d98a3340d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.1)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4a463-8266-45b8-954a-7b55fade3075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609d42f-2b4f-4496-abe3-5c305a06610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\", max_length=512\n",
    ")\n",
    "\n",
    "from llama_index.core import Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598247d-25aa-40f2-98c2-32b139bbab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.embeddings.together import TogetherEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "api_key = \"\"\n",
    "\n",
    "embed_model = TogetherEmbedding(\n",
    "    model_name=\"togethercomputer/m2-bert-80M-32k-retrieval\", api_key=api_key\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5df3e4-6c27-4c58-9625-6ba09a499961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f95749e1-9f25-4b3c-a717-aeb350e50211",
   "metadata": {
    "tags": []
   },
   "source": [
    "### index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a571022-888f-4081-860e-2541f5defe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "        SimpleKeywordTableIndex,\n",
    "\n",
    ")\n",
    "from llama_index.core import SummaryIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e3644-7498-475b-a597-7f3daf89e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.schema import IndexNode\n",
    "\n",
    "vector_obj = IndexNode(\n",
    "    index_id=\"vector\", obj=vector_retriever, text=\"Vector Retriever\"\n",
    ")\n",
    "bm25_obj = IndexNode(\n",
    "    index_id=\"bm25\", obj=bm25_retriever, text=\"BM25 Retriever\"\n",
    ")\n",
    "SummaryIndex(objects=[vector_obj, bm25_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b906bb-4789-48d3-ad98-1553dadfad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_index = SummaryIndex(nodes, storage_context=storage_context)\n",
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "keyword_index = SimpleKeywordTableIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b069d2e-ad2b-46ae-8450-206f7890cb63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 索引存储"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ea5ab-5f88-423b-abbe-0bd9c6c5343b",
   "metadata": {},
   "source": [
    "#### 本地化存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "993593ea-de78-442a-a7a4-800a6cb3f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"aabc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ed026-bed9-4759-858f-a4b184ca4164",
   "metadata": {},
   "source": [
    "#### 加载本地化索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9134223d-3845-43d7-a812-d379c31664db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"aabc\")\n",
    "\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d0810-84e5-492e-af97-2998e63507ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
