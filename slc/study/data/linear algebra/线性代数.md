# 线性代数

## 基本的知识架构体系





## 基本概念

> ​	线性：线性指量与量之间按比例，成直线的关系，在数学上可以理解为一阶导数为常数的函数。
>
> ​	向量：指具有大小和方向的量。
>
> ​	标量
>
> ​	张量：是一个定义在的一些向量空间和一些对偶空间的笛卡尔积上的多线性映射，其坐标是｜n｜维空间内，有｜n｜个分量的一种量，其中每一个分量都是坐标的函数，而在坐标变换时，这些分量也按照某些规则作线性变换。r称为该张量的秩或阶

在同构的意义下，第零阶张量（r = 0）为标量（Scalar），第一阶张量（r = 1）

为向量（Vector），第二阶张量（r = 2）则成为矩阵（matrix）。例如，对于3维空间，r = 1时的张量为此向量：（x，y，z）

## 矩阵

只有方阵才有行列式

矩阵乘法有三种：数乘，点乘，矩阵乘法 （np.dot)

### 矩阵的初等变换

1交换矩阵的两行或者两列

2以不为零的数k乘某一行或者一列的所有元素

3 把某一行（列）所有元素的K倍加到另一行（列）对应的元素上

若矩阵A经过有限次的初等变换变成了矩阵B，那么A等于B 矩阵等价用符号～表示

### 矩阵的逆矩阵

​	方阵A可逆的充分必要条件是A的模不等于0 且
$$
A^{-1} = \frac1{|A|}A^* 其中A^*为伴随矩阵
$$

$$
其中A_{ij}表示除去a_{ij}所在行和列后得到的n-1阶行列式乘以（-1）^{i+j}
$$

### 其他矩阵

正定矩阵（>0）

负定矩阵（<0）

半正定矩阵（>=0）

半负定矩阵（<=0）

奇异矩阵（0）不可逆

特征矩阵（海森矩阵/黑塞矩阵）：用来判断函数的凹凸性

雅可比矩阵  ：用来判断函数的单调性

### 几种特殊的矩阵

$$
AA^T = E (E为单位矩阵，A^T表示“矩阵A的转置矩阵”)或A^TA = E
$$

$$
则n阶实矩阵A称为正交矩阵
$$

## 行列式

表示完备矩阵的大小

行列式计算

行列式的性质

最小二乘法

## 线性相关性

### 向量组的线性相关性

![截屏2020-08-25 下午7.02.43](/Users/zhaoxuefeng/Library/Mobile Documents/com~apple~CloudDocs/图片/截屏2020-08-25 下午7.02.43.png)

### 正相关/负相关/不相关

内积为0表示不相关，小于0是负相关，大于0是正相关，绝对值越大，表示相关性越大

比较两组向量相关性的前提：放在同一个参考系中（把两个向量变成一样长）（归一化）

范数

我们以后把一个向量或者张量的长度变为1的过程叫做归一化

向量的相关性和不相关性主要用来建立坐标系

如果这两个向量可以用来表示空间的坐标系，那么我们把这两个向量叫做基

一组无关的向量如果能够完整的表达整个空间，那么我们把它称为完备基

### 其他

$$
y = wx
$$

$$
x = yw^{-1}
$$

$$
\frac1w = \frac{w^T}{w·w^T} = w^T(ww^T)^{-1}
$$

![截屏2020-08-25 下午3.56.32](/Users/zhaoxuefeng/Library/Mobile Documents/com~apple~CloudDocs/图片/截屏2020-08-25 下午3.56.32.png)

### 余弦相似度

$$
similarity = cos（\theta） = \frac{A·B}{||A||||B||}
$$

### 矩阵特征值

![截屏2020-09-02 上午10.35.07](/Users/zhaoxuefeng/Library/Mobile Documents/com~apple~CloudDocs/图片/截屏2020-09-02 上午10.35.07.png)

如果我们以结果为导向，要对一个向量进行变换，乘以一个矩阵就可以了。如果我们想看一下，这个矩阵会对向量产生什么样的结果，只要计算出他的特征值就知道了

### 相似矩阵

相似矩阵是用来换坐标系的

### 矩阵分解

奇异值分解 降维

矩阵的特征值以及对应的特征向量和相似变换在实际机器学习中是姜维和奇异值分解

SVD（特征值分解）

LDA（线性判别分析）

PCA（主成分分析法）

