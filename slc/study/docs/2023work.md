# 未来格局展望

# 回顾过去
模型底层的搭建:
模型服务的搭建 Triton 华为
模型的量化,部署


运用层:
知识库 思维链
多表生成
lora训练
stable diffusion 

***speak: 我们从无到有的构建起了大模型的框架,介绍介绍***


# 展望未来
2023年chatGPT的诞生,加速了整个世界的节奏,改变了AI生态,从GPT3,gpt3.5 到 gpt4 再到各种开源模型.GPT3.5     -》 new bing  -》 GPT4.0  -》 LLAMA 大模型开源  -》 stable diffusion LLama 2  stable diffusion 1.0 -> langchain  今年是大模型的元年,从整个年头道年尾 都被大模型技术轰炸,
我想结合这一年我看到的,实际操作的手感,谈谈我对于大模型的一些洞见.

结合我这一年对于人工智能各个方面的研究 以及结合我自己编写网络时的亲自的感受

个人观点   
第一  思维编程将取代现有编程      
第二  强化学习 + GPT 更接近强人工智能


## 思维编程将取代现有编程




### 什么是思维编程
我们已经达成一致的观点是,当下的编程语言会消失,但是怎么消失,消失之后会以什么形态存在

未来的编程会存在什么样的样态 看法是不同的 我认为 未来会存在思维编程

举个例子

理发店 的思维逻辑 

问好 -》 查看顾客情况 -》 了解顾客喜好 -》 开始剪发 -》 沟通 -》 推销产品 -》 送别



# 1 编程的历史就是不断集成化的历史

从汇编语言 到C 、 C++ 再到 现在各种更高级语言 Java JavaScript 等 Python

编程语言的发展本质上就是不断的集成。

单片机中 有时必须用汇编语言，汇编语言仍然可以实现c/c++ 无法实现的精准控制 但是C、C++ 已经取代了汇编语言 99%的工作  C语言显得要更简洁 但是底层要更粗糙

编程语言的前进，本质上是资源规模不断扩充带来的便捷性大于性能的（规模代替效率）改变

编程语言向着简单化  便捷化发展

最后肯定是大多数市场被抢占 而原生语言只负责特定需求的共存局面



## 2 在GPT的加持下，让本来就快速的自动化，集成化 变得更加没有局限和变得更快

为什么思维编程可以集成现有程序

GPT4 已经可以写出大部分的功能，

MetaGPT 是基于GPT4 进行开发的prompt项目 目前已经可以实现项目化的代码编写

SD mdj 解决人文的问题

目前 GPT4 可能无法解决的问题是

极致的性能问题

复杂的bug问题

这些都可以通过规模和规范化接口来实现

当前语言都不会消失

1 从历史来看 就是封装和集成的历史
汇编  c  c++  python
2 现在的LLM 已经有能力编写相当准确的代码

3 当前已经的集成形态过于累赘

4 思维连的形态以及成果
如果智能体存在 ,我们能做什么

## 3 目前的AI能力 作为一个智能体可能仍有不足，但作为一个思维节点则搓搓有余

目前的工作

MetaGPT 提出了模拟人格的概念 做了

Prompt 工程

之前的AgentGPT 

很多论文提到的 思维连 进化成思维网 思维树等



其实就是将复杂的认知问题拆解化，交给很多大模型或者多次调用去实现

但是还应该更近一步

但但的思维连不足够 而应该具备完整的逻辑体系工具



## 4 思维练的编程语言化，或是最优解

目前的思维连 思维网 都过于保守 应该更近一步

编程有完成的思维体系

实现与或非 循环 条件判断等

语言本身就有简洁的特点



其中已经有一些人做了一些尝试

Nvidia 提出了 colang语言 在nemograirail中配合围栏使用

langchain 也基于python 自定义 了 新语法 ，或者说语言 

但这些语言都是一些浅尝则止 或者说是一些便捷性的方案

langchain 对比

如果是一门语言就 会有自己的生态 自己的包 IDE 社区等等附属的产品



## 5 思维编程的桎梏

编程思维无法打破人类模式 不管是GPT 的过往经验 还是编程方式都是来自于人类

大模型的计算逻辑本质上就是计算上一句话 下一个字的概率

。。。。











 #  强化学习 + GPT 更合理的强人工智能

纵览所有AI技术 除了强化学习以外 ，再无任何一个技术打破人类模式

其他所有的AI 技术都是通过学习人类的数据，可以说是被人类指导，

什么是强化学习

其他AI 例如绘图是学习一个东西的分布

那么强化学习就是概率的动力学版本

它有点像练鼓

直接与环境交互

比如alfa go

战胜人类



## 1 强化学习的致命弱点 没有传承

强化学习 因为与环境交互 所以 只能在基础环境中训练

训练时间之长，设计奖励机制的复杂 无异于炼丹

而且训练好的版本只能当前使用 经验无法迁移



强化学习喂养大模型的思路
1 转变了模型学习概率的方式
2 中文有中文的编码方式 英文有英文的编码方式  
编码方式的统一
3如何继承
把GPT放在前面
现在没有吗?
将多个强化学习连接起来

## 2与GPT结合或可解决传承问题

3 大模型的计算逻辑是什么  大模型的本质 实际上是计算下一个词的出现概率 

结合方案

语言不止语言本身 ,真正的语言在语言之外



## 3 解决传承问题的最有一片平图

训练数据

数字孪生也好 元宇宙也好 都会产生大量的数据和工作环境来提供寻来你



## 4 强化学习版本下的合成数据

优质数据 

数字智能体

结合数字孪生,打造进一步的数字孪生

将强化学习从游戏 带到现实







# 未来的格局很可能是两者并存

## 1 GPT + 强化学习的优势

端到端才是最优解

1 吴恩达说过

2 机器学习到深度学习的过程就是去人工的过程

3 强化学习在围棋界以无对手 







## 2 思维编程的优势

可控：可控 安全 永远是最吸引人的词汇

透明 每一个环境都可以设置权限 每一个部分都可以进行日志 替换 编程





## 3 可能的使用方式

 AI + 仿真

1 分析特定轨道布局的车祸、分析服务器集群的部署效率

2 退火算法

强化学习 寻找最优解

社区 人际关系分析  工位设计  基本一切的场景

只要单个模型可以做到足够的精细 那么仿真的结果就可以预测未来

重构社会学 经济学体系

优化路径设计 优化。。。



建立另类科技树 突破人类模式



## 还需要哪些技术的成熟

编程

​	等待一个生态的形成

强化

​	等待数字孪生的成熟

​	经验迁移的成功






## 合成数据

1 苹果汁

合成数据

做小领域的大模型 
而不是大领域的小模型






 











