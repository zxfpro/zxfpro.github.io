{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./imge/CLBLOGO.jpg\" alt=\"创乐博\" style=\"width: 300px;\"/></center>\n",
    "\n",
    "# 22.基于百度语音实时播报识别物体对象\n",
    "\n",
    "@－－－－湖南创乐博智能科技有限公司－－－－<br>\n",
    "@  文件名：22.基于百度语音实时播报识别物体对象.ipynb <br>\n",
    "@  版本：V2.0 <br>\n",
    "@  author: zhulin<br>\n",
    "@  说明：基于百度语音实时播报识别物体对象<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.pyttsx3 离线版语音引擎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate',150)\n",
    "engine.setProperty('voice','english+f2')\n",
    "text = 'Welcome to Makerobo AI speech recognition system!!'\n",
    "engine.say(text)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing raw data 'makerobo.mp3' : Unsigned 8 bit, Rate 8000 Hz, Mono\n"
     ]
    }
   ],
   "source": [
    "!aplay makerobo.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.基于百度语音实时播放识别物体对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import jetson.inference\n",
    "import jetson.utils\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak = True\n",
    "item = '欢迎使用创乐博AI智能语音识别系统！！'\n",
    "confidence = 0\n",
    "itemOld=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7d6eb8d58b45d5ac8cf8fa48158c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='720', width='1280')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "frame_img = widgets.Image(format='jpeg', width=1280, height=720)\n",
    "display(frame_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0 (SDL 2.0.8, python 3.6.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from aip import AipSpeech\n",
    "import pygame\n",
    "import threading # 线程\n",
    "\n",
    "#这里需要填你自己的id和密钥\n",
    "APP_ID='16226519'\n",
    "API_KEY='5KVxQVES4LSja0u2G4y8m1O9'\n",
    "SECRET_KEY='KhaXYwGLSmQYgnwHkuXKpV9MO2ta0bQ8'\n",
    "aipSpeech=AipSpeech(APP_ID,API_KEY,SECRET_KEY)\n",
    "\n",
    "def sayItem():\n",
    "    global speak\n",
    "    global item\n",
    "    while True:\n",
    "        if speak == True:\n",
    "            result = aipSpeech.synthesis(text = item,options={'spd':5,'vol':9,'per':0,})\n",
    "            if not isinstance(result,dict):\n",
    "                with open('makerobo.mp3','wb') as f:\n",
    "                    f.write(result)\n",
    "                    \n",
    "            else:print(result)\n",
    "            #我们利用Jetson Nano自带的pygame\n",
    "            pygame.mixer.init()\n",
    "            pygame.mixer.music.load('./makerobo.mp3')\n",
    "            pygame.mixer.music.play()\n",
    "            speak=False\n",
    "\n",
    "x = threading.Thread(target=sayItem,daemon=True)\n",
    "x.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispW=1280\n",
    "dispH=720\n",
    "flip=4\n",
    "        \n",
    "# Gstreamer code for improvded Raspberry Pi Camera Quality\n",
    "camSet='nvarguscamerasrc wbmode=3 tnr-mode=2 tnr-strength=1 ee-mode=2 ee-strength=1 ! video/x-raw(memory:NVMM), width=3264, height=2464, format=NV12, framerate=21/1 ! nvvidconv flip-method='+str(flip)+' ! video/x-raw, width='+str(dispW)+', height='+str(dispH)+', format=BGRx ! videoconvert ! video/x-raw, format=BGR ! videobalance contrast=1.5 brightness=-.2 saturation=1.2 ! appsink'\n",
    "cam=cv2.VideoCapture(camSet)\n",
    "\n",
    "net=jetson.inference.imageNet('googlenet')\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "timeMark= time.time()\n",
    "fpsFiltered=0\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    img = cv2.cvtColor(frame,cv2.COLOR_BGR2RGBA).astype(np.float32)\n",
    "    img = jetson.utils.cudaFromNumpy(img)\n",
    "    \n",
    "    if speak == False:\n",
    "        classID,confidence = net.Classify(img,dispW,dispH)\n",
    "        if confidence>=.5:\n",
    "            item=net.GetClassDesc(classID)\n",
    "            if item!=itemOld:\n",
    "                speak = True\n",
    "        if confidence < .5:\n",
    "            item=''\n",
    "        itemOld = item\n",
    "    dt = time.time() - timeMark\n",
    "    timeMark = time.time()\n",
    "    fps = 1/dt\n",
    "    fpsFiltered=.95*fpsFiltered + .05*fps\n",
    "    cv2.putText(frame,str(round(fpsFiltered,1)) + ' fps '+item+str(round(confidence,2)),(0,30),font,1,(0,0,255),2)\n",
    "    frame_img.value = bgr8_to_jpeg(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
